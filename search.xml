<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>kafka使用总结</title>
      <link href="/2020/09/02/kafka%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"/>
      <url>/2020/09/02/kafka%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>​ &emsp;&emsp;Kafka 是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由 LinkedIn 公司开发，使用<br>Scala 语言编写，目前是 Apache 的开源项目。</p><a id="more"></a><ol><li>broker：Kafka 服务器，负责消息存储和转发</li><li>topic：消息类别，Kafka 按照 topic 来分类消息</li><li>partition：topic 的分区，一个 topic 可以包含多个 partition，topic 消息保存在各个<br>partition 上</li><li>offset：消息在日志中的位置，可以理解是消息在 partition 上的偏移量，也是代表该消息的<br>唯一序号</li><li>Producer：消息生产者</li><li>Consumer：消息消费者</li><li>Consumer Group：消费者分组，每个 Consumer 必须属于一个 group</li><li>Zookeeper：保存着集群 broker、topic、partition 等 meta 数据；另外，还负责 broker 故<br>障发现，partition leader 选举，负载均衡等功能</li></ol><h4 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h4><p><strong>partition 的数据文件</strong>（ offset，MessageSize，data ）<br> &emsp;&emsp;partition中的每条Message包含了以下三个属性：offset，MessageSize，data，其中offset表示 Message 在这个 partition 中的偏移量，offset 不是该 Message 在 partition 数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了partition中的一条Message，可以认为offset是partition 中 Message 的 id；MessageSize 表示消息内容 data 的大小；data 为 Message 的具体内容。<br><strong>数据文件分段 segment</strong>（ 顺序读写、分段命令、二分查找 ）<br> &emsp;&emsp;partition 物理上由多个 segment 文件组成，每个 segment 大小相等，顺序读写。每个 segment数据文件以该段中最小的 offset 命名，文件扩展名为.log。这样在查找指定 offset 的 Message 的时候，用二分查找就可以定位到该 Message 在哪个 segment 数据文件中。<br><strong>数据文件索引</strong>（分段索引、 稀疏存储 ）<br> &emsp;&emsp;Kafka 为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为.index。index 文件中并没有为数据文件中的每条 Message 建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。</p><h4 id="生产者设计"><a href="#生产者设计" class="headerlink" title="生产者设计"></a>生产者设计</h4><h5 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h5><p>​ &emsp;&emsp;由于消息 topic 由多个 partition 组成，且 partition 会均衡分布到不同 broker 上，因此，为了有效利用 broker 集群的性能，提高消息的吞吐量，producer 可以通过随机或者 hash 等方式，将消息平均发送到多个 partition 上，以实现负载均衡。</p><h5 id="批量发送"><a href="#批量发送" class="headerlink" title="批量发送"></a>批量发送</h5><p>​ &emsp;&emsp;是提高消息吞吐量重要的方式，Producer 端可以在内存中合并多条消息后，以一次请求的方式发送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响了消息的实时性，相当于以时延代价，换取更好的吞吐量。</p><h5 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h5><p>​ &emsp;&emsp;Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后，在Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是 CPU（压缩和解压会耗掉部分 CPU 资源）。</p><h4 id="消费者设计"><a href="#消费者设计" class="headerlink" title="消费者设计"></a>消费者设计</h4><h5 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h5><p>​ &emsp;&emsp;同一 Consumer Group 中的多个 Consumer 实例，不同时消费同一个 partition，等效于队列模式。partition 内消息是有序的，Consumer 通过 pull 方式消费消息。Kafka 不删除已消费的消息对于 partition，顺序读写磁盘数据，以时间复杂度 O(1)方式提供消息持久化能力。</p><h4 id="可靠性的保证"><a href="#可靠性的保证" class="headerlink" title="可靠性的保证"></a>可靠性的保证</h4><p>下面通过从topic的分区副本、producer发送到broker、leader选举三个方面来阐述kafka的可靠性。</p><h5 id="Topic的分区副本"><a href="#Topic的分区副本" class="headerlink" title="Topic的分区副本"></a>Topic的分区副本</h5><p>​ &emsp;&emsp;其实在kafka-0.8.0之前的版本是还没有副本这个概念的，在之后版本引入了副本这个架构，每个分区设置几个副本，可以在设置主题的时候可以通过replication-factor参数来设置，也可以在broker级别中设置defalut.replication-factor来指定，一般我们都设置为3；<br>​ &emsp;&emsp;三个副本中有一个副本是leader，两个副本是follower，leader负责消息的读写，follower负责定期从leader中复制最新的消息，保证follower和leader的消息一致性，当leader宕机后，会从follower中选举出新的leader负责读写消息，通过分区副本的架构，虽然引入了数据冗余，但是保证了kafka的高可靠。<br>​ &emsp;&emsp;Kafka的分区多副本是Kafka可靠性的核心保证，把消息写入到多个副本可以使Kafka在崩溃时保证消息的持久性及可靠性。</p><h5 id="Producer发送消息到broker"><a href="#Producer发送消息到broker" class="headerlink" title="Producer发送消息到broker"></a>Producer发送消息到broker</h5><p>​ &emsp;&emsp;topic的每个分区内的事件都是有序的，但是各个分区间的事件不是有序的，producer发送消息到broker时通过acks参数来确认消息是否发送成功,request.required.acks参数有三个值来代表不同的含义;<br>​ &emsp;&emsp;acks=0：表示只要producer通过网络传输将消息发送给broker，那么就会认为消息已经成功写入Kafka；但是如果网卡故障或者发送的对象不能序列化就会错误；<br>​ &emsp;&emsp;acks=1：表示发送消息的消息leader已经接收并写入到分区数据文件中，就会返回成功或者错误的响应，如果这时候leader发生选举，生产者会再次发送消息直到新的leader接收并写入分区文件；但是这种方式还是可能发生数据丢失，当follower还没来得及从leader中复制最新的消息，leader就宕机了，那么这时候就会造成数据丢失；<br>​ &emsp;&emsp;acks=-1：代表leader和follower都已经成功写入消息是才会返回确认的响应，但是这种方式效率最低，因为要等到当前消息已经被leader和follower都写入返回响应才能继续下条消息的发送；<br>所以根据不用的业务场景，设置不同的acks值，当然producer发送消息有两种方式：同步和异步，异步的方式虽然能增加消息发送的性能，但是会增加数据丢失风险，所以为了保证数据的可靠性，需要将发送方式设置为同步(sync)。</p><h5 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h5><p>​ &emsp;&emsp;在每个分区的leader都会维护一个ISR列表，ISR里面就是follower在broker的编号，只有跟得上leader的follower副本才能加入到ISR列表，只有这个列表里面的follower才能被选举为leader，所以在leader挂了的时候，并且unclean.leader.election.enable=false(关闭不完全的leader选举)的情况下，会从ISR列表中选取第一个follower作为新的leader，来保证消息的高可靠性。</p><p>&emsp;&emsp;综上所述，要保证kafka消息的可靠性，至少需要配置一下参数：</p><ul><li>topic级别：replication-factor&gt;=3；</li><li>producer级别：acks=-1；同时发送模式设置producer.type=sync；</li><li>broker级别：关闭不完全的leader选举，即unclean.leader.election.enable=false;</li></ul><h4 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h4><p>这里说的一致性指的是不管是老的leader还是新的leader，consumer都能读到一样的数据。<br><img src="https://img-blog.csdnimg.cn/20190825165607196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg4ODgwNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> &emsp;&emsp;假设分区副本为3，副本0位leader，副本1和2位follower，在ISR列表里面副本0已经写入了message4，但是consumer只能读取message2，这是因为所有副本都同步了message2，只有High water mark以上的message才能被consumer读取，而High water mark取决于ISR列表里偏移量最小的分区，对应上图中的副本2；<br> &emsp;&emsp;所以在message还没有被follower同步完成时会被认为是”不安全的”，如果consumer读取了副本0中的message4，这时候leader挂了，选举了副本1为新的leader，别的消费者去消费的时候就没有message4，就会造成不同的consumer消费的数据不一致，破坏了数据的一致性。<br> &emsp;&emsp;在0.08版本引入了<strong>High water mark</strong>机制后，会导致broker之间的消息复制因为某些原因变慢，消息到达消费者的时间也会延长(需要等消息复制完了才能消费)，延迟的时间可以通过参数来设置：replica.lag.time.max.ms(它指定了副本在复制消息时可被允许的最大延迟时间)</p><p>​ &emsp;&emsp;0.11.0.0版本的Kafka通过引入<strong>leader epoch</strong>解决了原先依赖水位表示副本进度可能造成的数据丢失/数据不一致问题。</p><h4 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h4><h5 id="Kafka-的设计时什么样的呢？"><a href="#Kafka-的设计时什么样的呢？" class="headerlink" title="Kafka 的设计时什么样的呢？"></a>Kafka 的设计时什么样的呢？</h5><ul><li>Kafka 将消息以 topic 为单位进行归纳</li><li>将向 Kafka topic 发布消息的程序成为 producers.</li><li>将预订 topics 并消费消息的程序成为 consumer.</li><li>Kafka 以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 broker.</li><li>producers 通过网络将消息发送到 Kafka 集群，集群向消费者提供消息</li></ul><h5 id="数据传输的事务定义有哪三种？"><a href="#数据传输的事务定义有哪三种？" class="headerlink" title="数据传输的事务定义有哪三种？"></a>数据传输的事务定义有哪三种？</h5><p>&emsp;&emsp;数据传输的事务定义通常有以下三种级别：</p><ul><li>最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输</li><li>最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</li><li>精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的</li></ul><h5 id="Kafka-判断一个节点是否还活着有那两个条件？"><a href="#Kafka-判断一个节点是否还活着有那两个条件？" class="headerlink" title="Kafka 判断一个节点是否还活着有那两个条件？"></a>Kafka 判断一个节点是否还活着有那两个条件？</h5><ul><li>节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连<br>接</li><li>如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久</li></ul><h5 id="Producer-是否直接将数据发送到-broker-的-leader-主节点-？"><a href="#Producer-是否直接将数据发送到-broker-的-leader-主节点-？" class="headerlink" title="Producer 是否直接将数据发送到 broker 的 leader(主节点)？"></a>Producer 是否直接将数据发送到 broker 的 leader(主节点)？</h5><p>​ &emsp;&emsp;producer 直接将数据发送到 broker 的 leader(主节点)，不需要在多个节点进行分发，为了帮助 producer 做到这点，所有的 Kafka 节点都可以及时的告知:哪些节点是活动的，目标topic 目标分区的 leader 在哪。这样 producer 就可以直接将消息发送到目的地了</p><h5 id="Kafa-consumer-是否可以消费指定分区消息？"><a href="#Kafa-consumer-是否可以消费指定分区消息？" class="headerlink" title="Kafa consumer 是否可以消费指定分区消息？"></a>Kafa consumer 是否可以消费指定分区消息？</h5><p>​ &emsp;&emsp;Kafa consumer 消费消息时，向 broker 发出”fetch”请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer 拥有了 offset 的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的</p><h5 id="Kafka-消息是采用-Pull-模式，还是-Push-模式？"><a href="#Kafka-消息是采用-Pull-模式，还是-Push-模式？" class="headerlink" title="Kafka 消息是采用 Pull 模式，还是 Push 模式？"></a>Kafka 消息是采用 Pull 模式，还是 Push 模式？</h5><p>​ &emsp;&emsp;Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消息推送到consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从 broker 拉取消息一些消息系统比如 Scribe 和 Apache Flume 采用了 push 模式，将消息推送到下游的consumer。这样做有好处也有坏处：由 broker 决定消息推送的速率，对于不同消费速率的consumer 就不太好处理了。消息系统都致力于让 consumer 以最大的速率最快速的消费消息，但不幸的是，push 模式下，当 broker 推送的速率远大于 consumer 消费的速率时，consumer 恐怕就要崩溃了。最终 Kafka 还是选取了传统的 pull 模式。</p><p>​ &emsp;&emsp;Pull 模式的另外一个好处是 consumer 可以自主决定是否批量的从 broker 拉取数据。Push模式必须在不知道下游 consumer 消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免 consumer 崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。Pull 模式下，consumer 就可以根据自己的消费能力去决定这些策略。Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询，直到新消息到达。为了避免这点，Kafka 有个参数可以让 consumer 阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发</p><h5 id="Kafka-存储在硬盘上的消息格式是什么？"><a href="#Kafka-存储在硬盘上的消息格式是什么？" class="headerlink" title="Kafka 存储在硬盘上的消息格式是什么？"></a>Kafka 存储在硬盘上的消息格式是什么？</h5><p>&emsp;&emsp;消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和 CRC32校验码。</p><ul><li>消息长度: 4 bytes (value: 1+4+n)</li><li>版本号: 1 byte</li><li>CRC 校验码: 4 bytes</li><li>具体的消息: n bytes</li></ul><h5 id="Kafka-高效文件存储设计特点"><a href="#Kafka-高效文件存储设计特点" class="headerlink" title="Kafka 高效文件存储设计特点"></a>Kafka 高效文件存储设计特点</h5><ul><li>Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定<pre><code>期清除或删除已经消费完文件，减少磁盘占用。</code></pre></li><li>通过索引信息可以快速定位 message 和确定 response 的最大大小。</li><li>通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。</li><li>通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小。</li></ul><h5 id="Kafka-与传统消息系统之间有三个关键区别"><a href="#Kafka-与传统消息系统之间有三个关键区别" class="headerlink" title="Kafka 与传统消息系统之间有三个关键区别"></a>Kafka 与传统消息系统之间有三个关键区别</h5><ul><li>Kafka 持久化日志，这些日志可以被重复读取和无限期保留</li><li>Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据<pre><code>提升容错能力和高可用性</code></pre></li><li>Kafka 支持实时的流式处理</li></ul><h5 id="Kafka-创建-Topic-时如何将分区放置到不同的-Broker-中"><a href="#Kafka-创建-Topic-时如何将分区放置到不同的-Broker-中" class="headerlink" title="Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中"></a>Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中</h5><ol><li>副本因子不能大于 Broker 的个数；</li><li>第一个分区（编号为 0）的第一个副本放置位置是随机从 brokerList 选择的；</li><li>其他分区的第一个副本放置位置相对于第 0 个分区依次往后移。也就是如果我们有 5 个<pre><code>Broker，5 个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个Broker 上，依次类推；</code></pre></li><li>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是<pre><code>随机产生的</code></pre></li></ol><h5 id="Kafka-新建的分区会在哪个目录下创建"><a href="#Kafka-新建的分区会在哪个目录下创建" class="headerlink" title="Kafka 新建的分区会在哪个目录下创建"></a>Kafka 新建的分区会在哪个目录下创建</h5><p>​ &emsp;&emsp;在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录，这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘上用于提高读写性能。 当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个目录下创建文件夹用于存放数据。</p><p>​ &emsp;&emsp;但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？</p><p>​ &emsp;&emsp;答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic名+分区 ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。</p><h5 id="Partition-的数据如何保存到硬盘"><a href="#Partition-的数据如何保存到硬盘" class="headerlink" title="Partition 的数据如何保存到硬盘"></a>Partition 的数据如何保存到硬盘</h5><p>​ &emsp;&emsp;topic 中的多个 partition 以文件夹的形式保存到 broker，每个分区序号从 0 递增，且消息有序Partition 文件下有多个 segment（xxx.index，xxx.log）segment 文件里的大小和配置文件大小一致可以根据要求修改默认为 1g，如果大小大于 1g 时，会滚动一个新的 segment 并且以上一个 segment 最后一条消息的偏移量命名</p><h5 id="kafka-的-ack-机制"><a href="#kafka-的-ack-机制" class="headerlink" title="kafka 的 ack 机制"></a>kafka 的 ack 机制</h5><p>​request.required.acks 有三个值 0  1  -1</p><ul><li>0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候<pre><code>就会丢数据</code></pre></li><li>1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader 挂掉后他<pre><code>不确保是否复制完成新 leader 也会导致数据丢失</code></pre></li><li>-1：同样在 1 的基础上 服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出<pre><code>的 ack，这样数据不会丢失</code></pre></li></ul><h5 id="Kafka-的消费者如何消费数据"><a href="#Kafka-的消费者如何消费数据" class="headerlink" title="Kafka 的消费者如何消费数据"></a>Kafka 的消费者如何消费数据</h5><p>​ &emsp;&emsp;消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置等到下次消费时，他会接着上次位置继续消费</p><h5 id="消费者负载均衡策略"><a href="#消费者负载均衡策略" class="headerlink" title="消费者负载均衡策略"></a>消费者负载均衡策略</h5><p>​ &emsp;&emsp;一个消费者组中的一个分片对应一个消费者成员，他能保证每个消费者成员都能访问，如果组中成员太多会有空闲的成员</p><h5 id="数据有序"><a href="#数据有序" class="headerlink" title="数据有序"></a>数据有序</h5><p>​ &emsp;&emsp;一个消费者组里它的内部是有序的，消费者组与消费者组之间是无序的</p><h5 id="kafaka-生产数据时数据的分组策略"><a href="#kafaka-生产数据时数据的分组策略" class="headerlink" title="kafaka 生产数据时数据的分组策略"></a>kafaka 生产数据时数据的分组策略</h5><p>​ &emsp;&emsp;生产者决定数据产生到集群的哪个 partition 中，每一条消息都是以（key，value）格式。Key 是由生产者发送数据传入，所以生产者（key）决定了数据产生到集群的哪个 partition</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper使用总结</title>
      <link href="/2020/09/02/Zookeeper%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"/>
      <url>/2020/09/02/Zookeeper%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="面试官：工作中使用过Zookeeper嘛？你知道它是什么，有什么用途呢？"><a href="#面试官：工作中使用过Zookeeper嘛？你知道它是什么，有什么用途呢？" class="headerlink" title="面试官：工作中使用过Zookeeper嘛？你知道它是什么，有什么用途呢？"></a>面试官：工作中使用过Zookeeper嘛？你知道它是什么，有什么用途呢？</h3><ul><li>有使用过的，使用ZooKeeper作为<strong>dubbo的注册中心</strong>，使用ZooKeeper实现<strong>分布式锁</strong>。</li><li>ZooKeeper，它是一个开放源码的<strong>分布式协调服务</strong>，它是一个集群的管理者，它将简单易用的接口提供给用户。</li><li>可以基于Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列<strong>等功能</strong>。</li><li>Zookeeper的<strong>用途</strong>：命名服务、配置管理、集群管理、分布式锁、队列管理</li></ul><p>用途跟功能不是一个意思咩？给我一个眼神，让我自己体会</p><a id="more"></a><h3 id="面试官：说下什么是命名服务，什么是配置管理，又什么是集群管理吧"><a href="#面试官：说下什么是命名服务，什么是配置管理，又什么是集群管理吧" class="headerlink" title="面试官：说下什么是命名服务，什么是配置管理，又什么是集群管理吧"></a>面试官：说下什么是命名服务，什么是配置管理，又什么是集群管理吧</h3><ul><li><strong>命名服务</strong>： 命名服务是指通过<strong>指定的名字</strong>来获取资源或者服务地址。Zookeeper可以创建一个<strong>全局唯一的路径</strong>，这个路径就可以作为一个名字。被命名的实体可以是<strong>集群中的机器，服务的地址，或者是远程的对象</strong>等。一些分布式服务框架（RPC、RMI）中的服务地址列表，通过使用命名服务，客户端应用能够根据特定的名字来获取资源的实体、服务地址和提供者信息等。举例来说，B服务部署在六台服务器上，存在六个完全不同的ip地址，同时B服务本身提供一个dubbo接口对外，此时有个A服务需要调用此接口，如果提供某一台服务器的ip，则存在该服务器宕机情况下接口不可用的情况，再切换ip就会影响服务的正常使用。此时，可以使用zookeeper作为注册中心，B服务的六台服务在指定znode下创建子节点，而A服务调用之前先通过指定znode的路径获取B服务的任意子节点中的ip信息，然后通过ip访问。同时zookeeper动态维护这部分节点，定时利用心跳请求检查B服务的服务器状态，一旦发现某服务器无反馈，就删除节点，防止被A服务获取调用</li><li><strong>配置管理：</strong> ： 实际项目开发中，我们经常使用.properties或者xml需要配置很多信息，如数据库连接信息、fps地址端口等等。因为你的程序一般是分布式部署在不同的机器上（如果你是单机应用当我没说），如果把程序的这些配置信息<strong>保存在zk的znode节点</strong>下，当你要修改配置，即znode会发生变化时，可以通过改变zk中某个目录节点的内容，利用<strong>watcher通知给各个客户端</strong>，从而更改配置。</li><li><strong>集群管理</strong> 集群管理包括集群监控和集群控制，其实就是监控集群机器状态，剔除机器和加入机器。zookeeper可以方便集群机器的管理，它可以实时监控znode节点的变化，一旦发现有机器挂了，该机器就会与zk断开连接，对用的临时目录节点会被删除，其他所有机器都收到通知。新机器加入也是类似酱紫，所有机器收到通知：有新兄弟目录加入啦。</li></ul><h3 id="面试官：你提到了znode节点，那你知道znode有几种类型呢？zookeeper的数据模型是怎样的呢？"><a href="#面试官：你提到了znode节点，那你知道znode有几种类型呢？zookeeper的数据模型是怎样的呢？" class="headerlink" title="面试官：你提到了znode节点，那你知道znode有几种类型呢？zookeeper的数据模型是怎样的呢？"></a>面试官：你提到了znode节点，那你知道znode有几种类型呢？zookeeper的数据模型是怎样的呢？</h3><p><strong>zookeeper的数据模型</strong></p><p> &emsp;&emsp;ZooKeeper的视图数据结构，很像Unix文件系统，也是树状的，这样可以确定每个路径都是唯一的。zookeeper的节点统一叫做<strong>znode</strong>，它是可以通过<strong>路径来标识</strong>，结构图如下：</p><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/2770c2d5a8f04eab80d7f0c5116cac55?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p><strong>znode的4种类型</strong></p><p>​ &emsp;&emsp;根据节点的生命周期，znode可以分为4种类型，分别是持久节点（PERSISTENT）、持久顺序节点（PERSISTENT_SEQUENTIAL）、临时节点（EPHEMERAL）、临时顺序节点（EPHEMERAL_SEQUENTIAL）</p><ul><li>持久节点（PERSISTENT） 这类节点被创建后，就会一直存在于Zk服务器上。直到手动删除。</li><li>持久顺序节点（PERSISTENT_SEQUENTIAL） 它的基本特性同持久节点，不同在于增加了顺序性。父节点会维护一个自增整性数字，用于子节点的创建的先后顺序。</li><li>临时节点（EPHEMERAL） 临时节点的生命周期与客户端的会话绑定，一旦客户端会话失效（非TCP连接断开），那么这个节点就会被自动清理掉。zk规定临时节点只能作为叶子节点。</li><li>临时顺序节点（EPHEMERAL_SEQUENTIAL） 基本特性同临时节点，添加了顺序的特性。</li></ul><h3 id="面试官：你知道znode节点里面存储的是什么吗？每个节点的数据最大不能超过多少呢？"><a href="#面试官：你知道znode节点里面存储的是什么吗？每个节点的数据最大不能超过多少呢？" class="headerlink" title="面试官：你知道znode节点里面存储的是什么吗？每个节点的数据最大不能超过多少呢？"></a>面试官：你知道znode节点里面存储的是什么吗？每个节点的数据最大不能超过多少呢？</h3><p>znode节点里面存储的是什么？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataNode</span> <span class="keyword">implements</span> <span class="title">Record</span> </span>&#123;</span><br><span class="line">    <span class="keyword">byte</span> data[];                    </span><br><span class="line">    Long acl;                           </span><br><span class="line">    <span class="keyword">public</span> StatPersisted stat;       </span><br><span class="line">    <span class="keyword">private</span> Set&lt;String&gt; children = <span class="keyword">null</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​ &emsp;&emsp;哈哈，Znode包含了<strong>存储数据、访问权限、子节点引用、节点状态信息</strong>，如图：</p><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/8a8a5152129848009b141729b626a1c9?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li><strong>data:</strong> znode存储的业务数据信息</li><li><strong>ACL:</strong> 记录客户端对znode节点的访问权限，如IP等。</li><li><strong>child:</strong> 当前节点的子节点引用</li><li><p><strong>stat:</strong> 包含Znode节点的状态信息，比如<strong>事务id、版本号、时间戳</strong>等等。</p><p>每个节点的数据最大不能超过多少呢</p></li></ul><p>​ &emsp;&emsp;为了保证高吞吐和低延迟，以及数据的一致性，znode只适合存储非常小的数据，不能超过1M，最好都小于1K。</p><h3 id="面试官：你知道znode节点上的监听机制嘛？讲下Zookeeper-watch机制吧。"><a href="#面试官：你知道znode节点上的监听机制嘛？讲下Zookeeper-watch机制吧。" class="headerlink" title="面试官：你知道znode节点上的监听机制嘛？讲下Zookeeper watch机制吧。"></a>面试官：你知道znode节点上的监听机制嘛？讲下Zookeeper watch机制吧。</h3><p><strong>Watcher监听机制</strong></p><p>​ &emsp;&emsp;Zookeeper 允许客户端向服务端的某个Znode注册一个Watcher监听，当服务端的一些指定事件触发了这个Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 Watcher通知状态和事件类型做出业务上的改变。</p><blockquote><p>可以把Watcher理解成客户端注册在某个Znode上的触发器，当这个Znode节点发生变化时（增删改查），就会触发Znode对应的注册事件，注册的客户端就会收到异步通知，然后做出业务的改变。</p></blockquote><p><strong>Watcher监听机制的工作原理</strong></p><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/6aee92ac8a5e41a6837076f392f23cd4?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li>ZooKeeper的Watcher机制主要包括客户端线程、客户端 WatcherManager、Zookeeper服务器三部分。</li><li>客户端向ZooKeeper服务器注册Watcher的同时，会将Watcher对象存储在客户端的WatchManager中。</li><li>当zookeeper服务器触发watcher事件后，会向客户端发送通知， 客户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑。</li></ul><p><strong>Watcher特性总结</strong></p><ul><li><strong>一次性：</strong>一个Watch事件是一个一次性的触发器。一次性触发，客户端只会收到一次这样的信息。</li><li><strong>异步的:</strong> Zookeeper服务器发送watcher的通知事件到客户端是异步的，不能期望能够监控到节点每次的变化，Zookeeper只能保证最终的一致性，而无法保证强一致性。</li><li><strong>轻量级：</strong> Watcher 通知非常简单，它只是通知发生了事件，而不会传递事件对象内容。</li><li><strong>客户端串行：</strong> 执行客户端 Watcher 回调的过程是一个串行同步的过程。</li><li>注册 watcher用getData、exists、getChildren方法</li><li>触发 watcher用create、delete、setData方法</li></ul><h3 id="面试官：你对Zookeeper的数据结构都有一定了解，那你讲下Zookeeper的特性吧"><a href="#面试官：你对Zookeeper的数据结构都有一定了解，那你讲下Zookeeper的特性吧" class="headerlink" title="面试官：你对Zookeeper的数据结构都有一定了解，那你讲下Zookeeper的特性吧"></a>面试官：你对Zookeeper的数据结构都有一定了解，那你讲下Zookeeper的特性吧</h3><p>Zookeeper 保证了如下分布式一致性特性：</p><ul><li><strong>顺序一致性</strong>：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</li><li><strong>原子性</strong>：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</li><li><strong>单一视图</strong>：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</li><li><strong>可靠性：</strong> 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来。</li><li><strong>实时性（最终一致性）：</strong> Zookeeper 仅仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。</li></ul><h3 id="面试官：你刚提到顺序一致性，那zookeeper是如何保证事务的顺序一致性的呢？"><a href="#面试官：你刚提到顺序一致性，那zookeeper是如何保证事务的顺序一致性的呢？" class="headerlink" title="面试官：你刚提到顺序一致性，那zookeeper是如何保证事务的顺序一致性的呢？"></a>面试官：你刚提到顺序一致性，那zookeeper是如何保证事务的顺序一致性的呢？</h3><p>这道题可以看下这篇文章（本题答案来自该文章）：聊一聊ZooKeeper的顺序一致性</p><blockquote><p>需要了解事务ID，即zxid。ZooKeeper的在选举时通过比较各结点的zxid和机器ID选出新的主结点的。zxid由Leader节点生成，有新写入事件时，Leader生成新zxid并随提案一起广播，每个结点本地都保存了当前最近一次事务的zxid，zxid是递增的，所以谁的zxid越大，就表示谁的数据是最新的。</p></blockquote><p>ZXID的生成规则如下：</p><p><img src="https://p1-tt.byteimg.com/origin/pgc-image/33fdc0e736e34d7785a0822b963b67ab?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>ZXID有两部分组成：</p><ul><li>任期：完成本次选举后，直到下次选举前，由同一Leader负责协调写入；</li><li>事务计数器：单调递增，每生效一次写入，计数器加一。</li></ul><blockquote><p>ZXID的低32位是计数器，所以同一任期内，ZXID是连续的，每个结点又都保存着自身最新生效的ZXID，通过对比新提案的ZXID与自身最新ZXID是否相差“1”，来保证事务严格按照顺序生效的。</p></blockquote><h3 id="面试官：你提到了Leader，你知道Zookeeper的服务器有几种角色嘛？Zookeeper下Server工作状态又有几种呢？"><a href="#面试官：你提到了Leader，你知道Zookeeper的服务器有几种角色嘛？Zookeeper下Server工作状态又有几种呢？" class="headerlink" title="面试官：你提到了Leader，你知道Zookeeper的服务器有几种角色嘛？Zookeeper下Server工作状态又有几种呢？"></a>面试官：你提到了Leader，你知道Zookeeper的服务器有几种角色嘛？Zookeeper下Server工作状态又有几种呢？</h3><p>Zookeeper集群中，有Leader、Follower和Observer三种角色</p><p><strong>Leader</strong></p><blockquote><p>Leader服务器是整个ZooKeeper集群工作机制中的核心，其主要工作：</p><p>事务请求的唯一调度和处理者，保证集群事务处理的顺序性 集群内部各服务的调度者</p></blockquote><p><strong>Follower</strong></p><blockquote><p>Follower服务器是ZooKeeper集群状态的跟随者，其主要工作：</p><p>处理客户端非事务请求，转发事务请求给Leader服务器 参与事务请求Proposal的投票 参与Leader选举投票</p></blockquote><p><strong>Observer</strong></p><blockquote><p>Observer是3.3.0 版本开始引入的一个服务器角色，它充当一个观察者角色——观察ZooKeeper集群的最新状态变化并将这些状态变更同步过来。其工作：</p><p>处理客户端的非事务请求，转发事务请求给 Leader 服务器 不参与任何形式的投票</p></blockquote><p>Zookeeper下Server工作状态</p><blockquote><p>服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、OBSERVING。</p><p>1.LOOKING：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。 </p><p>2.FOLLOWING：跟随者状态。表明当前服务器角色是Follower。 </p><p>3.LEADING：领导者状态。表明当前服务器角色是Leader。 </p><p>4.OBSERVING：观察者状态。表明当前服务器角色是Observer。</p></blockquote><h3 id="面试官：你说到服务器角色是基于ZooKeeper集群的，那你画一下ZooKeeper集群部署图吧？ZooKeeper是如何保证主从节点数据一致性的呢？"><a href="#面试官：你说到服务器角色是基于ZooKeeper集群的，那你画一下ZooKeeper集群部署图吧？ZooKeeper是如何保证主从节点数据一致性的呢？" class="headerlink" title="面试官：你说到服务器角色是基于ZooKeeper集群的，那你画一下ZooKeeper集群部署图吧？ZooKeeper是如何保证主从节点数据一致性的呢？"></a>面试官：你说到服务器角色是基于ZooKeeper集群的，那你画一下ZooKeeper集群部署图吧？ZooKeeper是如何保证主从节点数据一致性的呢？</h3><p>ZooKeeper集群部署图</p><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/68de19e989124b11b40aa90bea89adbb?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>ZooKeeper集群是一主多从的结构：</p><ul><li>如果是写入数据，先写入主服务器（主节点），再通知从服务器。</li><li>如果是读取数据，既读主服务器的，也可以读从服务器的。</li></ul><p>ZooKeeper如何保证主从节点数据一致性</p><p>&emsp;&emsp;我们知道集群是主从部署结构，要保证主从节点一致性问题，无非就是两个主要问题：</p><ul><li><strong>主服务器挂了，或者重启了</strong></li><li><strong>主从服务器之间同步数据</strong>~</li></ul><p>&emsp;&emsp;Zookeeper是采用ZAB协议（Zookeeper Atomic Broadcast，Zookeeper原子广播协议）来保证主从节点数据一致性的，ZAB协议支持<strong>崩溃恢复和消息广播</strong>两种模式，很好解决了这两个问题：</p><ul><li>崩溃恢复：Leader挂了，进入该模式，选一个新的leader出来</li><li>消息广播： 把更新的数据，从Leader同步到所有Follower</li></ul><blockquote><p>Leader服务器挂了，所有集群中的服务器进入LOOKING状态，首先，它们会选举产生新的Leader服务器；接着，新的Leader服务器与集群中Follower服务进行数据同步，当集群中超过半数机器与该 Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式。Leader 服务器开始接收客户端的事务请求生成事务Proposal进行事务请求处理。</p></blockquote><h3 id="面试官：Leader挂了，进入崩溃恢复，是如何选举Leader的呢？你讲一下ZooKeeper选举机制吧"><a href="#面试官：Leader挂了，进入崩溃恢复，是如何选举Leader的呢？你讲一下ZooKeeper选举机制吧" class="headerlink" title="面试官：Leader挂了，进入崩溃恢复，是如何选举Leader的呢？你讲一下ZooKeeper选举机制吧"></a>面试官：Leader挂了，进入崩溃恢复，是如何选举Leader的呢？你讲一下ZooKeeper选举机制吧</h3><p>服务器启动的Leader选举</p><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/419fc446a9e74f2c85d2402d48e931b5?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>zookeeper集群初始化阶段，服务器（myid=1-5）<strong>依次</strong>启动，开始zookeeper选举Leader~</p><ul><li>服务器1（myid=1）启动，当前只有一台服务器，无法完成Leader选举</li><li>服务器2（myid=2）启动，此时两台服务器能够相互通讯，开始进入Leader选举阶段 每个服务器发出一个投票 服务器1 和 服务器2都将自己作为Leader服务器进行投票，投票的基本元素包括：服务器的myid和ZXID，我们以（myid，ZXID）形式表示。初始阶段，服务器1和服务器2都会投给自己，即服务器1的投票为（1,0），服务器2的投票为（2,0），然后各自将这个投票发给集群中的其他所有机器。 接受来自各个服务器的投票 每个服务器都会接受来自其他服务器的投票。同时，服务器会校验投票的有效性，是否本轮投票、是否来自LOOKING状态的服务器。 处理投票 收到其他服务器的投票，会将被人的投票跟自己的投票PK，PK规则如下： 优先检查ZXID。ZXID比较大的服务器优先作为leader。 如果ZXID相同的话，就比较myid，myid比较大的服务器作为leader。 服务器1的投票是（1,0），它收到投票是（2,0），两者zxid都是0，因为收到的myid=2，大于自己的myid=1，所以它更新自己的投票为（2,0），然后重新将投票发出去。对于服务器2呢，即不再需要更新自己的投票，把上一次的投票信息发出即可。 统计投票 每次投票后，服务器会统计所有投票，判断是否有过半的机器接受到相同的投票信息。服务器2收到两票，少于3（n/2+1,n为总服务器），所以继续保持LOOKING状态</li><li>服务器3（myid=3）启动，继续进入Leader选举阶段 跟前面流程一致，服务器1和2先投自己一票，因为服务器3的myid最大，所以大家把票改投给它。此时，服务器为3票（大于等于n/2+1）,所以服务器3当选为Leader。 服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；</li><li>服务器4启动，发起一次选举。 此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。选票信息结果：服务器3为4票，服务器4为1票。服务器4并更改状态为FOLLOWING；</li><li>服务器5启动，发起一次选举。 同理，服务器也是把票投给服务器3，服务器5并更改状态为FOLLOWING；</li><li>投票结束，服务器3当选为Leader</li></ul><p>服务器运行期间的Leader选举</p><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/8f8d0fc897d1420ab1ec38c5fc886ecd?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>zookeeper集群的五台服务器（myid=1-5）正在运行中，突然某个瞬间，Leader服务器3挂了，这时候便开始Leader选举~</p><ul><li>1.变更状态 Leader 服务器挂了之后，余下的非Observer服务器都会把自己的服务器状态更改为LOOKING，然后开始进入Leader选举流程。</li><li>2.每个服务器发起投票 每个服务器都把票投给自己，因为是运行期间，所以每台服务器的ZXID可能不相同。假设服务1,2,4,5的zxid分别为333,666,999,888，则分别产生投票（1,333），（2，666），（4,999）和（5,888），然后各自将这个投票发给集群中的其他所有机器。</li><li>3.接受来自各个服务器的投票</li><li>4.处理投票 投票规则是跟Zookeeper集群启动期间一致的，优先检查ZXID，大的优先作为Leader，所以显然服务器zxid=999具有优先权。</li><li>5.统计投票</li><li>6.改变服务器状态</li></ul><h3 id="面试官：-你前面提到在项目中使用过Zookeeper的分布式锁，讲一下zk分布式锁的实现原理吧？"><a href="#面试官：-你前面提到在项目中使用过Zookeeper的分布式锁，讲一下zk分布式锁的实现原理吧？" class="headerlink" title="面试官： 你前面提到在项目中使用过Zookeeper的分布式锁，讲一下zk分布式锁的实现原理吧？"></a>面试官： 你前面提到在项目中使用过Zookeeper的分布式锁，讲一下zk分布式锁的实现原理吧？</h3><p>Zookeeper就是使用临时顺序节点特性实现分布式锁的。</p><ul><li>获取锁过程 （创建临时节点，检查序号最小）</li><li>释放锁 （删除临时节点，监听通知）</li></ul><p>获取锁过程</p><ul><li>当第一个客户端请求过来时，Zookeeper客户端会创建一个持久节点/locks。如果它（Client1）想获得锁，需要在locks节点下创建一个顺序节点lock1.如图</li></ul><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/fb3dd97205814643a941e94eece1763e?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li>接着，客户端Client1会查找locks下面的所有临时顺序子节点，判断自己的节点lock1是不是排序最小的那一个，如果是，则成功获得锁。</li></ul><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/b32a098c251f48e19f8b678ba83a26a1?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li>这时候如果又来一个客户端client2前来尝试获得锁，它会在locks下再创建一个临时节点lock2</li></ul><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/3608918374f34d68a80d78d87d522805?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li>客户端client2一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock2是不是最小的，此时，发现lock1才是最小的，于是获取锁失败。获取锁失败，它是不会甘心的，client2向它排序靠前的节点lock1注册Watcher事件，用来监听lock1是否存在，也就是说client2抢锁失败进入等待状态。</li></ul><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/d750b3d812954f448a7954c2e0cfe6e0?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li>此时，如果再来一个客户端Client3来尝试获取锁，它会在locks下再创建一个临时节点lock3</li></ul><p><img src="https://p1-tt.byteimg.com/origin/pgc-image/d56dbf13e6d0474b82daebe11e4bd5ba?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><ul><li>同样的，client3一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock3是不是最小的，发现自己不是最小的，就获取锁失败。它也是不会甘心的，它会向在它前面的节点lock2注册Watcher事件，以监听lock2节点是否存在。</li></ul><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/c89f1c25c6b141be8a310e30a4e00793?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p><strong>释放锁</strong></p><p>我们再来看看释放锁的流程，zookeeper的<strong>客户端业务完成或者故障</strong>，都会删除临时节点，释放锁。如果是任务完成，Client1会显式调用删除lock1的指令</p><p><img src="https://p3-tt.byteimg.com/origin/pgc-image/1f3b58beb4d3412fafa9c4ee805d5432?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>如果是客户端故障了，根据临时节点得特性，lock1是会自动删除的</p><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/8dba6d6ab65044e185a4976791237efa?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>lock1节点被删除后，Client2可开心了，因为它一直监听着lock1。lock1节点删除，Client2立刻收到通知，也会查找locks下面的所有临时顺序子节点，发下lock2是最小，就获得锁。</p><p><img src="https://p1-tt.byteimg.com/origin/pgc-image/b306b6a02f9447748604b12d443cd744?from=pc" alt="面试官的ZooKeeper的十二连问，我怎么顶得住啊"></p><p>同理，Client2获得锁之后，Client3也对它虎视眈眈，啊哈哈~</p><h3 id="面试官：好的，最后一道题，你说说dubbo和Zookeeper的关系吧，为什么选择Zookeeper作为注册中心？"><a href="#面试官：好的，最后一道题，你说说dubbo和Zookeeper的关系吧，为什么选择Zookeeper作为注册中心？" class="headerlink" title="面试官：好的，最后一道题，你说说dubbo和Zookeeper的关系吧，为什么选择Zookeeper作为注册中心？"></a>面试官：好的，最后一道题，你说说dubbo和Zookeeper的关系吧，为什么选择Zookeeper作为注册中心？</h3><p>dubbo的注册中心可以选Zookeeper，memcached，redis等。为什么选择Zookeeper，因为它的功能特性咯~</p><ul><li>命名服务，服务提供者向Zookeeper指定节点写入url，完成服务发布。</li><li>负载均衡，注册中心的承载能力有限，而Zookeeper集群配合web应用很容易达到负载均衡。</li><li>zk支持监听事件，特别适合发布/订阅的场景，dubbo的生产者和消费者就类似这场景。</li><li>数据模型简单，数据存在内存，可谓高性能</li><li>Zookeeper其他特点都可以搬出来讲一下~</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper使用实例——服务节点管理</title>
      <link href="/2020/08/30/Zookeeper%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B%E2%80%94%E2%80%94%E6%9C%8D%E5%8A%A1%E8%8A%82%E7%82%B9%E7%AE%A1%E7%90%86/"/>
      <url>/2020/08/30/Zookeeper%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B%E2%80%94%E2%80%94%E6%9C%8D%E5%8A%A1%E8%8A%82%E7%82%B9%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p> &emsp;&emsp;分布式处理中，总会存在多个服务节点同时工作，并且节点数量会随着网络规模的变化而动态增减，服务节点也有可能发生宕机与恢复。面对着动态增减的服务节点，我们如何保证客户请求被服务器正确处理呢。我们可以通过zookeeper临时节点创建与自动删除来掌握服务节点的动态增减。<br><a id="more"></a></p><p>​&emsp;&emsp;ignite分布式缓存支持使用zookeeper发现ignite节点的增减，这正是zookeeper管理服务节点的一个典型应用场景。我们来看看关键代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 关键方法，创建包含自增长id名称的目录，这个方法支持了分布式锁的实现</span></span><br><span class="line"><span class="comment">// 四个参数：</span></span><br><span class="line"><span class="comment">// 1、目录名称 2、目录文本信息 </span></span><br><span class="line"><span class="comment">// 3、文件夹权限，Ids.OPEN_ACL_UNSAFE表示所有权限 </span></span><br><span class="line"><span class="comment">// 4、目录类型，CreateMode.EPHEMERAL_SEQUENTIAL表示创建临时目录，session断开连接则目录自动删除</span></span><br><span class="line">String createdPath = zk.create(</span><br><span class="line">    <span class="string">"/"</span> + clusterNode + <span class="string">"/"</span> + serverNode, </span><br><span class="line">    address.getBytes(<span class="string">"utf-8"</span>), </span><br><span class="line">    Ids.OPEN_ACL_UNSAFE, </span><br><span class="line">    CreateMode.EPHEMERAL_SEQUENTIAL);</span><br></pre></td></tr></table></figure><p>​&emsp;&emsp;<strong>采用CreateMode.EPHEMERAL_SEQUENTIAL模式创建临时节点，可以支持服务节点的实时管理</strong>。没错，这个模式和《<a href="http://www.cnblogs.com/coshaho/p/6995558.html" target="_blank" rel="noopener">Zookeeper使用实例——分布式共享锁</a>》中创建有序节点支持分布式共享锁是一致的。EPHEMERAL_SEQUENTIAL表示创建有序的临时目录节点，zookeeper客户端创建临时节点后，只要session断开，该临时节点会自动删除。</p><p>​&emsp;&emsp;所以，服务器在zookeeper上创建一个临时目录节点，通过节点事件监听我们可以知道服务器已经加入到服务网络中，监听到临时目录节点删除事件，我们可以知道该节点对应的服务器已经脱离服务网络。下面我们看看具体代码</p><h3 id="服务器启动后在zookeeper创建临时目录"><a href="#服务器启动后在zookeeper创建临时目录" class="headerlink" title="服务器启动后在zookeeper创建临时目录"></a>服务器启动后在zookeeper创建临时目录</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.coshaho.learn.zookeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs.Ids;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 服务节点启动后注册到zookeeper</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> coshaho</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppServer</span> <span class="keyword">extends</span> <span class="title">Thread</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String clusterNode = <span class="string">"Locks"</span>;</span><br><span class="line">    <span class="keyword">private</span> String serverNode = <span class="string">"mylock"</span>;</span><br><span class="line">    <span class="keyword">private</span> String serverName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sleepTime;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> </span><br><span class="line">        &#123;</span><br><span class="line">            connectZookeeper(serverName);</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">catch</span> (Exception e) </span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connectZookeeper</span><span class="params">(String address)</span> <span class="keyword">throws</span> Exception </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        ZooKeeper zk = <span class="keyword">new</span> ZooKeeper(<span class="string">"192.168.1.104:12181"</span>, <span class="number">5000</span>, <span class="keyword">new</span> Watcher() </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span></span><br><span class="line"><span class="function">            </span>&#123;&#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关键方法，创建包含自增长id名称的目录，这个方法支持了分布式锁的实现</span></span><br><span class="line">        <span class="comment">// 四个参数：</span></span><br><span class="line">        <span class="comment">// 1、目录名称 2、目录文本信息 </span></span><br><span class="line">        <span class="comment">// 3、文件夹权限，Ids.OPEN_ACL_UNSAFE表示所有权限 </span></span><br><span class="line">        <span class="comment">// 4、目录类型，CreateMode.EPHEMERAL_SEQUENTIAL表示创建临时目录，session断开连接则目录自动删除</span></span><br><span class="line">        String createdPath = zk.create(</span><br><span class="line">                <span class="string">"/"</span> + clusterNode + <span class="string">"/"</span> + serverNode, </span><br><span class="line">                address.getBytes(<span class="string">"utf-8"</span>), </span><br><span class="line">                Ids.OPEN_ACL_UNSAFE, </span><br><span class="line">                CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">        System.out.println(<span class="string">"create: "</span> + createdPath);</span><br><span class="line">        Thread.sleep(sleepTime);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AppServer</span><span class="params">(String serverName, <span class="keyword">long</span> sleepTime)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.serverName = serverName;</span><br><span class="line">        <span class="keyword">this</span>.sleepTime = sleepTime;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="节点管理服务监听zookeeper临时目录节点创建删除事件"><a href="#节点管理服务监听zookeeper临时目录节点创建删除事件" class="headerlink" title="节点管理服务监听zookeeper临时目录节点创建删除事件"></a>节点管理服务监听zookeeper临时目录节点创建删除事件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.coshaho.learn.zookeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher.Event.EventType;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 客户端注册监听server节点变化</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> coshaho</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppMaster</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String clusterNode = <span class="string">"Locks"</span>;</span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zk;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> List&lt;String&gt; serverList;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connectZookeeper</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 注册全局默认watcher</span></span><br><span class="line">        zk = <span class="keyword">new</span> ZooKeeper(<span class="string">"192.168.1.104:12181"</span>, <span class="number">5000</span>, <span class="keyword">new</span> Watcher() </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span></span><br><span class="line"><span class="function">            </span>&#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 有以下几种事件</span></span><br><span class="line"><span class="comment">                 * None</span></span><br><span class="line"><span class="comment">                 * NodeCreated  节点被创建</span></span><br><span class="line"><span class="comment">                 * NodeDeleted  节点被删除</span></span><br><span class="line"><span class="comment">                 * NodeDataChanged  节点数据更新</span></span><br><span class="line"><span class="comment">                 * NodeChildrenChanged  子节点变更</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> (event.getType() == EventType.NodeChildrenChanged </span><br><span class="line">                        &amp;&amp; (<span class="string">"/"</span> + clusterNode).equals(event.getPath())) </span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">try</span> </span><br><span class="line">                    &#123;</span><br><span class="line">                        updateServerList();</span><br><span class="line">                    &#125; </span><br><span class="line">                    <span class="keyword">catch</span> (Exception e) </span><br><span class="line">                    &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        updateServerList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateServerList</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        List&lt;String&gt; newServerList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// watcher注册后，只能监听事件一次，参数true表示继续使用默认watcher监听事件</span></span><br><span class="line">        List&lt;String&gt; subList = zk.getChildren(<span class="string">"/"</span> + clusterNode, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">for</span> (String subNode : subList)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 获取节点数据</span></span><br><span class="line">            <span class="keyword">byte</span>[] data = zk.getData(<span class="string">"/"</span> + clusterNode + <span class="string">"/"</span> + subNode, <span class="keyword">false</span>, <span class="keyword">null</span>);</span><br><span class="line">            newServerList.add(<span class="keyword">new</span> String(data, <span class="string">"utf-8"</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        serverList = newServerList;</span><br><span class="line">        System.out.println(<span class="string">"server list updated: "</span> + serverList);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        AppMaster ac = <span class="keyword">new</span> AppMaster();</span><br><span class="line">        ac.connectZookeeper();</span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动两个服务器"><a href="#启动两个服务器" class="headerlink" title="启动两个服务器"></a>启动两个服务器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.coshaho.learn.zookeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server1</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        AppServer server1 = <span class="keyword">new</span> AppServer(<span class="string">"Server1"</span>, <span class="number">5000</span>);</span><br><span class="line">        server1.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.coshaho.learn.zookeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server2</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        AppServer server1 = <span class="keyword">new</span> AppServer(<span class="string">"Server2"</span>, <span class="number">10000</span>);</span><br><span class="line">        server1.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j:<span class="function">WARN No appenders could be found <span class="keyword">for</span> <span class="title">logger</span> <span class="params">(org.apache.zookeeper.ZooKeeper)</span>.</span></span><br><span class="line"><span class="function">log4j:WARN Please initialize the log4j system properly.</span></span><br><span class="line"><span class="function">log4j:WARN See http:<span class="comment">//logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span></span></span><br><span class="line"><span class="function">server list updated: []</span></span><br><span class="line"><span class="function">server list updated: [Server1]</span></span><br><span class="line"><span class="function">server list updated: [Server2, Server1]</span></span><br><span class="line"><span class="function">server list updated: [Server2]</span></span><br><span class="line"><span class="function">server list updated: []</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink Table 的三种 Sink 模式</title>
      <link href="/2020/08/09/Flink-Table-%E7%9A%84%E4%B8%89%E7%A7%8D-Sink-%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/08/09/Flink-Table-%E7%9A%84%E4%B8%89%E7%A7%8D-Sink-%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="Flink简介"><a href="#Flink简介" class="headerlink" title="Flink简介"></a>Flink简介</h2><p>&emsp;&emsp;作为计算引擎 Flink 应用的计算结果总要以某种方式输出，比如调试阶段的打印到控制台或者生产阶段的写到数据库。而对于本来就需要在 Flink 内存保存中间及最终计算结果的应用来说，比如进行聚合统计的应用，输出结果便是将内存中的结果同步到外部。就 Flink Table/SQL API 而言，这里的同步会有三种模式，分别是 Append、Upsert 和 Retract。实际上这些输出计算结果的模式并不限于某个计算框架，比如 Storm、Spark 或者 Flink DataStream 都可以应用这些模式，不过 Flink Table/SQL 已有完整的概念和内置实现，更方便讨论。<br><a id="more"></a></p><h2 id="基础原理"><a href="#基础原理" class="headerlink" title="基础原理"></a>基础原理</h2><p>&emsp;&emsp;相信接触过 Streaming SQL 的同学都有了解或者听过流表二象性，简单来说流和表是同一事实的不同表现，是可以相互转换的。流和表的表述在业界不尽相同，笔者比较喜欢的一种是: 流体现事实在时间维度上的变化，而表则体现事实在某个时间点的视图。如果将流比作水管中流动的水，那么表将是杯子里静止的水。</p><p>&emsp;&emsp;将流转换为表的方法对于大多数读者都不陌生，只需将聚合统计函数应用到流上，流很自然就变为表（值得注意的是，Flink 的 Dynamic Table 和表的定义有细微不同，这将在下文讲述）。比如对于一个计算 PV 的简单流计算作业，将用户浏览日志数据流安 url 分类统计，变成 <code>(url, views)</code> 这样的一个表。然而对于如何将表转换成流，读者则未必有这么清晰的概念。</p><p>&emsp;&emsp;假设一个典型的实时流计算应用的工作流程可以被简化为下图:</p><p><a href="http://www.whitewood.me/img/flink-sink-pattern/img1.programing-model.png" target="_blank" rel="noopener"><img src="http://www.whitewood.me/img/flink-sink-pattern/img1.programing-model.png" alt="图1. Flink 编程模型"></a></p><p>&emsp;&emsp;其中很关键的一点是 Transformation 是否聚合类型的计算。若否，则输出结果依然是流，可以很自然地使用原本流处理的 Sink（与外部系统的连接器）；若是，则流会转换为表，那么输出的结果将是表，而一个表的输出通常是批处理的概念，不能直接简单地用流处理的 Sink 来表达。</p><p>&emsp;&emsp;这时有个很朴素的想法是，我们能不能避免批处理那种全量的输出，每次只输出表的 diff，也就是 changelog。这也是表转化为流的方法: 持续观察表的变化，并将每个变化记录成日志输出。因此，流和表的转换可以以下图表示:</p><p><a href="http://www.whitewood.me/img/flink-sink-pattern/img2.stream-table-conversion.png" target="_blank" rel="noopener"><img src="http://www.whitewood.me/img/flink-sink-pattern/img2.stream-table-conversion.png" alt="图2. Flink 编程模型"></a></p><p>&emsp;&emsp;其中表的变化具体可以分为 <code>INSERT</code>、<code>UPDATE</code> 和 <code>DELETE</code> 三类，而 Flink 根据这些变化类型分别总结了三种结果的输出模式。</p><table><thead><tr><th style="text-align:left">模式</th><th style="text-align:left">INSERT</th><th style="text-align:left">UPDATE</th><th style="text-align:left">DELETE</th></tr></thead><tbody><tr><td style="text-align:left">Append</td><td style="text-align:left">支持</td><td style="text-align:left">不支持</td><td style="text-align:left">不支持</td></tr><tr><td style="text-align:left">Upsert</td><td style="text-align:left">支持</td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left">Retract</td><td style="text-align:left">支持</td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr></tbody></table><p>&emsp;&emsp;通常来说 Append 是最容易实现但功能最弱的，Retract 是最难实现而功能最强的。下文分别谈谈三种模式的特点和应用场景。</p><h2 id="Append-输出模式"><a href="#Append-输出模式" class="headerlink" title="Append 输出模式"></a>Append 输出模式</h2><p>&emsp;&emsp;Append 是最为简单的输出模式，只支持追加结果记录的操作。因为结果一旦输出以后便不会再有变更，Append 输出模式的最大特性是不可变性（immutability），而不可变性最令人向往的优势便是安全，比如线程安全或者 Event Sourcing 的可恢复性，不过同时也会给业务操作带来限制。通常来说，Append 模式会用于写入不方便做撤回或者删除操作的存储系统的场景，比如 Kafka 等 MQ 或者打印到控制台。</p><p>&emsp;&emsp;在实时聚合统计中，聚合统计的结果输出是由 Trigger 决定的，而 Append-Only 则意味着对于每个窗口实例（Pane，窗格）Trigger 只能触发一次，则就导致无法在迟到数据到达时再刷新结果。通常来说，我们可以给 Watermark 设置一个较大的延迟容忍阈值来避免这种刷新（再有迟到数据则丢弃），但代价是却会引入较大的延迟。</p><p>&emsp;&emsp;不过对于不涉及聚合的 Table 来说，Append 输出模式是非常好用的，因为这类 Table 只是将数据流的记录按时间顺序排在一起，每条记录间的计算都是独立的。值得注意的是，从 DataFlow Model 的角度来看未做聚合操作的流不应当称为表，但是在 Flink 的概念里所有的流都可以称为 Dynamic Table。笔者认为这个设计也有一定的道理，原因是从流中截取一段出来依然可以满足表的定义，即”某个时间点的视图”，而且我们可以争辩说<code>不聚合</code>也是一种聚合函数。</p><h2 id="Upsert-输出模式"><a href="#Upsert-输出模式" class="headerlink" title="Upsert 输出模式"></a>Upsert 输出模式</h2><p>&emsp;&emsp;Upsert 是 Append 模式的升级版，支持 Append-Only 的操作和在有主键的前提下的 UPDATE 和 DELETE 操作。Upsert 模式依赖业务主键来实现输出结果的更新和删除，因此非常适合 KV 数据库，比如<br>HBase、JDBC 的 TableSink 都使用了这种方式。</p><p>&emsp;&emsp;在底层，Upsert 模式下的结果更新会被翻译为 (Boolean, ROW) 的二元组。其中第一个元素表示操作类型，<code>true</code> 对应 <code>UPSERT</code> 操作（不存在该元素则 <code>INSERT</code>，存在则 <code>UPDATE</code>），<code>false</code> 对应 <code>DELETE</code> 操作，第二个元素则是操作对应的记录。如果结果表本身是 Append-Only 的，第一个元素会全部为 <code>true</code>，而且也无需提供业务主键。</p><p>&emsp;&emsp;Upsert 模式是目前来说比较实用的模式，因为大部分业务都会提供原子或复合类型的主键，而在支持 KV 的存储系统也非常多，但要注意的是不要变更主键，具体原因会在下一节谈到。</p><h2 id="Retract-输出模式"><a href="#Retract-输出模式" class="headerlink" title="Retract 输出模式"></a>Retract 输出模式</h2><p>&emsp;&emsp;Retract 是三种输出模式中功能最强大但实现也最复杂的一种，它要求目标存储系统可以追踪每个条记录，而且这些记录至少在一定时间内都是可以撤回的，因此通常来说它会自带系统主键，不必依赖于业务主键。然而由于大数据存储系统很少有可以精确到一条记录的更新操作，因此目前来说至少在 Flink 原生的 TableSink 中还没有能在生产环境中满足这个要求的。</p><p>&emsp;&emsp;不同于 Upsert 模式更新时会将整条记录重新输出，Retract 模式会将更新分成两条表示增减量的消息，一条是 <code>(false, OldRow)</code> 的撤回（Retract）操作，一条是 <code>(true, NewRow)</code> 的积累（Accumulate）操作。这样的好处是，在主键出现变化的情况下，<code>Upsert</code> 输出模式无法撤回旧主键的记录，导致数据不准确，而 <code>Retract</code> 模式则不存在这个问题。</p><p>&emsp;&emsp;举个例子，假设我们将电商订单按照承运快递公司进行分类计数，有如下的结果表。</p><table><thead><tr><th style="text-align:left">公司</th><th style="text-align:left">订单数</th></tr></thead><tbody><tr><td style="text-align:left">中通</td><td style="text-align:left">2</td></tr><tr><td style="text-align:left">圆通</td><td style="text-align:left">1</td></tr><tr><td style="text-align:left">顺丰</td><td style="text-align:left">3</td></tr></tbody></table><p>&emsp;&emsp;那么如果原本一单为中通的快递，后续更新为用顺丰发货，对于 Upsert 模式会产生 <code>(true, (顺丰, 4))</code> 这样一条 changelog，但中通的订单数没有被修正。相比之下，Retract 模式产出 <code>(false, (中通, 1))</code> 和 <code>(true, (顺丰, 1))</code> 两条数据，则可以正确地更新数据。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&emsp;&emsp;Flink Table Sink 的三种模式本质上是如何监控结果表并产生 changelog，这可以应用于所有需要将表转为流的场景，包括同一个 Flink 应用的不同表间的联动。三种模式中 Append 模式只支持表的 <code>INSERT</code>，最为简单；Upsert 模式依赖业务主键提供 <code>INSERT</code>、<code>UPDATE</code> 和 <code>DELETE</code> 全部三类变更，比较实用；Retract 模式同样支持三类变更且不要求业务主键，但会将 <code>UPDATE</code> 翻译为旧数据的撤回和新数据的累加，实现上比较复杂。</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常用命令</title>
      <link href="/2019/04/22/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2019/04/22/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p> &emsp;&emsp;最近都在和Linux打交道，我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢Linux的原因，比较短小但却功能强大。<br><a id="more"></a></p><h2 id="文件目录"><a href="#文件目录" class="headerlink" title="文件目录"></a>文件目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir test        创建文件夹</span><br><span class="line">rm -rf /test      删除文件夹</span><br><span class="line">cd /test          切换文件夹</span><br><span class="line">pwd               查看文件夹路径</span><br><span class="line">cp -r test /root  拷贝文件夹目录</span><br><span class="line">mv test /root     移动文件夹、更改文件夹的名字</span><br><span class="line">ls ll          查看文件夹下文件</span><br></pre></td></tr></table></figure><h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">touch test.txt    新建文件</span><br><span class="line">cp test.txt newtest.txt 复制文件</span><br><span class="line">rm -f test.txt    删除文件</span><br><span class="line">cat test.txt      查看文件内容</span><br><span class="line">more test.txt     分屏显示文件内容  空格键显示下一页内容，B键显示上一页内容，Q键退出</span><br><span class="line">head -10 test.txt 打印文件1-10行</span><br><span class="line">tail -10 test.txt 打印最后10行内容</span><br><span class="line">tail -f test.txt  实时打印文件内容</span><br><span class="line">find 路径 -name test.txt 查找文件或目录，列出路径，可以使用正则表达式查找</span><br></pre></td></tr></table></figure><h2 id="vi-vim"><a href="#vi-vim" class="headerlink" title="vi/vim"></a>vi/vim</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">命令行模式 </span><br><span class="line">:w保存  </span><br><span class="line">:q退出  </span><br><span class="line">:q!不保存强制退出  </span><br><span class="line">:set nu显示行号 </span><br><span class="line">:/单词查找匹配</span><br><span class="line">:N,Md 删除N-M行数据</span><br><span class="line">一般模式：   </span><br><span class="line">yy复制当前行 </span><br><span class="line">    nyy复制下面n行 </span><br><span class="line">    p粘贴到下一行 P粘贴到上一行</span><br><span class="line">G移动到最后一行</span><br><span class="line">nG移动到第n行</span><br><span class="line">n+光标下移n行 </span><br><span class="line">    n-光标上移n行 </span><br><span class="line">H光标移动到屏幕顶行 </span><br><span class="line">    M光标移动到屏幕中间行 </span><br><span class="line">    L光标移动到屏幕最后行</span><br><span class="line">dd删除行   </span><br><span class="line">x删除光标后一个字符 X删除光标前一个字符 </span><br><span class="line">u恢复前一个动作</span><br></pre></td></tr></table></figure><h2 id="远程拷贝"><a href="#远程拷贝" class="headerlink" title="远程拷贝"></a>远程拷贝</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp [-r] test.txt root@node02:`pwd`   本地到远程</span><br><span class="line">scp [-r] root@node02:/test /root/     远程到本地</span><br></pre></td></tr></table></figure><h2 id="磁盘指令"><a href="#磁盘指令" class="headerlink" title="磁盘指令"></a>磁盘指令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df [-m][-k][-h]      查看硬盘信息</span><br><span class="line">du [-k][-m][-a][-h][-max-depth=0] /目录    查看目录信息</span><br></pre></td></tr></table></figure><h2 id="网络指令"><a href="#网络指令" class="headerlink" title="网络指令"></a>网络指令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ifconfig                          查看网络配置</span><br><span class="line">ping ip地址                        查看是否连通</span><br><span class="line">netstat                           查看网络相关信息</span><br><span class="line">telnet 192.168.198.111 22         测试远程主机网络端口  Ctrl+]   输入q退出</span><br><span class="line">curl -X GET http://www.baidu.com/ http请求模拟</span><br></pre></td></tr></table></figure><p>​          </p><h2 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">*用户操作指令：</span><br><span class="line">useradd ocean     添加用户，创建一个组</span><br><span class="line">passwd ocean      修改密码</span><br><span class="line">useradd -r ocean  删除用户</span><br><span class="line">usermod -l newocean ocean 修改用户名</span><br><span class="line">usermod -L ocean  锁定账号</span><br><span class="line">usermod -U ocean  解锁账号</span><br><span class="line">/etc/passwd   /etc/shodow    查看用户</span><br><span class="line">*用户组操作指令：</span><br><span class="line">groupadd groupname创建用户组</span><br><span class="line">groupdel groupname删除用户组</span><br><span class="line">groupmod -n newname name 修改用户组名</span><br><span class="line">groups   查看当前登录用户的组内成员</span><br><span class="line">groups ocean   查看指定用户所在组</span><br><span class="line">usermod [-g][-G] 组名 用户   修改用户的主组或者附加组</span><br><span class="line">cat /etc/group 查看组</span><br><span class="line"></span><br><span class="line">*文件权限：</span><br><span class="line">UGO模型：USER  GROUP  OTHER</span><br><span class="line">chown -R user:group 目录名字   修改整个目录下的所有者和属组</span><br><span class="line">chmod ugo+rwx test.txt  修改文件的权限</span><br><span class="line">chmod 700 test.txt  设置权限</span><br><span class="line"></span><br><span class="line">*系统服务初始化配置：</span><br><span class="line">0：停机状态</span><br><span class="line">1：单用户模式</span><br><span class="line">2：多用户</span><br><span class="line">3：完全多用户</span><br><span class="line">4：为定义</span><br><span class="line">5：图形化</span><br><span class="line">6：停止所有进程，重启</span><br><span class="line"></span><br><span class="line">*系统时间指令：</span><br><span class="line">date 查看时间</span><br><span class="line">date -s 时间  修改时间</span><br><span class="line">时间同步：</span><br><span class="line">yum -y install ntp</span><br><span class="line">ntpdate cn.ntp.org.cn</span><br><span class="line"></span><br><span class="line">*配置主机名：   </span><br><span class="line">vim /etc/sysconfig/network</span><br><span class="line"></span><br><span class="line">*配置域名映射： </span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">*sudo权限配置： </span><br><span class="line">vim /etc/sudoers</span><br><span class="line">sudo -l</span><br><span class="line"></span><br><span class="line">*环境变量：</span><br><span class="line">vim /etc/profile   全局</span><br><span class="line">echo $path  显示环境变量</span><br><span class="line">source /etc/profile  重新加载环境变量</span><br><span class="line">vi  ~/.bash_profile  临时</span><br><span class="line">  </span><br><span class="line">*防火墙：</span><br><span class="line">service iptables status查看状态</span><br><span class="line">    chkconfig iptables on/off 永久生效</span><br><span class="line">    service iptables start 即时生效</span><br></pre></td></tr></table></figure><h2 id="重定向和管道"><a href="#重定向和管道" class="headerlink" title="重定向和管道"></a>重定向和管道</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">输出重定向：&gt;    &gt;&gt;</span><br><span class="line">输入重定向：&lt;    &lt;&lt;</span><br><span class="line">标准输出重定向：  1&gt;</span><br><span class="line">错误输出重定向：  2&gt;</span><br><span class="line">结合使用：2&gt;&amp;1</span><br><span class="line">管道： |</span><br><span class="line">命令执行控制：&amp;&amp; 前一个命令执行成功才会执行后一个命令</span><br><span class="line">|| 前一个命令执行失败才会执行后一个命令</span><br><span class="line">信息黑洞：/dev/null</span><br></pre></td></tr></table></figure><h2 id="shell脚本"><a href="#shell脚本" class="headerlink" title="shell脚本"></a>shell脚本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">定义变量：name=&quot;ocean&quot;</span><br><span class="line">引用变量：$name</span><br><span class="line">数组：my_array=&#123;A,B,C,D&#125;        $&#123;my_array[0]&#125;</span><br><span class="line">运算符：</span><br><span class="line">表达式和运算符之间必须有空格</span><br><span class="line">完整的表达式要被 ` ` 包含</span><br><span class="line">val=`expr $a + $b` </span><br><span class="line">val=`expr $a - $b`</span><br><span class="line">val=`expr $a \* $b` </span><br><span class="line">val=`expr $b / $a` </span><br><span class="line">val=`expr $b % $a`</span><br><span class="line">$a == $b</span><br><span class="line">$a != $b</span><br><span class="line">-eq是否相等   -ne是否不相等   -gt左边是否大于右边   -lt左边是否小于右边    -ge左边是大于等于右边    -le左边是否小于等于右边</span><br><span class="line">&amp;&amp;   ||</span><br><span class="line">=字符串是否相等   !=是否不想等   -z长度是否为0   -n长度是否不为0    str是否为不为空</span><br><span class="line">流程控制</span><br><span class="line">函数test()&#123;&#125;</span><br></pre></td></tr></table></figure><h2 id="服务指令"><a href="#服务指令" class="headerlink" title="服务指令"></a>服务指令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">列出所有服务   chkconfig   </span><br><span class="line">service 服务名  start/stop/status/restart</span><br><span class="line">添加服务   /etc/init.d系统各种服务的启动和停止脚本</span><br><span class="line"> /etc/rc.d/ 系统对应执行级别的服务软连接</span><br><span class="line">步骤：在脚本中添加两行代码#chkconfig: 2345 80 90 #description:auto_run </span><br><span class="line"> 编写脚本</span><br><span class="line"> 修改可执行权限</span><br><span class="line"> 将脚本拷贝到/etc/init.d目录下</span><br><span class="line"> 加入到服务里chkconfig --add test.sh</span><br><span class="line"> 重启服务器</span><br><span class="line">删除服务：chkconfig --del name</span><br><span class="line">服务等级更改：chkconfig --level 2345 name off|on   默认是2345</span><br></pre></td></tr></table></figure><h2 id="定时调度"><a href="#定时调度" class="headerlink" title="定时调度"></a>定时调度</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">minute hour day month dayofweek 命令</span><br><span class="line">查看定时任务：/var/spool/mail  目录下放各用户定时任务，执行后的信息</span><br><span class="line">/var/spool/cron 目录存放每个用户的定时任务</span><br><span class="line">contab –l 可以直接查看当前用户的定时任务</span><br></pre></td></tr></table></figure><h2 id="linux安全"><a href="#linux安全" class="headerlink" title="linux安全"></a>linux安全</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">selinux  enforcing强制模式</span><br><span class="line"> permissive宽容模式</span><br><span class="line"> disabled关闭</span><br><span class="line">sestatus -v查看状态</span><br></pre></td></tr></table></figure><h2 id="linux进程"><a href="#linux进程" class="headerlink" title="linux进程"></a>linux进程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ps -aux查看进程   jobs -l</span><br><span class="line">ps -ef | grep ssh查看相关进程</span><br><span class="line">ps -aux --sort -pcpu根据CPU使用来升序排列</span><br><span class="line">top性能分析</span><br><span class="line">nohup /root/start.h &amp;  后台运行</span><br><span class="line">kill -9 杀死进程</span><br></pre></td></tr></table></figure><h2 id="解压压缩下载"><a href="#解压压缩下载" class="headerlink" title="解压压缩下载"></a>解压压缩下载</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yum下载</span><br><span class="line">wget下载</span><br><span class="line">RPM命令：rpm  –ivh  rpm包  安装</span><br><span class="line">rpm -q ntp        查找</span><br><span class="line">rpm –e 包名       卸载</span><br><span class="line">tar命令：tar  -zvxf  xxxx.tar.gz       解压</span><br><span class="line">tar -zcf 压缩包命名 压缩目标  压缩</span><br><span class="line">zip命令：zip -r 包名 目标目录    压缩</span><br><span class="line">unzip filename          解压</span><br></pre></td></tr></table></figure><p>​<br>​<br>​              </p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo博客搭建</title>
      <link href="/2019/04/16/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
      <url>/2019/04/16/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>&emsp;&emsp;最近一段时间比较闲，想着搭个博客玩玩，看了网上主流的博客网站，不是太喜欢，作为一个互联网行业的小渣渣，博客当然要自己搭才有意思了，于是在网上找了一些方案，最终选择了<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">hexo</a>+<a href="https://github.com/" target="_blank" rel="noopener">github</a>的方式来搭建个人博客。</p><p><img src="https://i.loli.net/2019/04/28/5cc54dc5075b4.png" alt></p><a id="more"></a><p>&emsp;&emsp;使用<strong>github pages</strong>服务搭建博客的好处有：</p><ol><li>全是静态文件，访问速度快；</li><li>免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；</li><li>可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；</li><li>数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；</li><li>博客内容可以轻松打包、转移、发布到其它平台；</li></ol><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>&emsp;&emsp;在你的博客之旅开始之前，首先要创建<strong>github</strong>账号，这个不做过多的介绍。登录你的github账户，创建一个名为<strong>你的用户名.github.io</strong>的仓库，将来你的博客访问地址就是这个啦。你也可以购买域名替换你的博客地址，当然这是要花钱的。</p><p>&emsp;&emsp;仓库建好后，我们需要在电脑上安装<strong>git</strong>和<strong>node.js</strong>，在这里要注意Git要提前配置好，和github做绑定，以后要用git工具将代码提交到github上保存的哦。<a href="https://nodejs.org/en/" target="_blank" rel="noopener">node.js</a> 因为整个博客框架是基于node.js的，所以必须安装node.js环境，安装过程中一路Next即可。</p><h2 id="安装hexo框架"><a href="#安装hexo框架" class="headerlink" title="安装hexo框架"></a>安装hexo框架</h2><p>&emsp;&emsp;准备工作做好后，我们就可以正式开始博客的搭建。<strong>Hexo</strong> 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>&emsp;&emsp;在桌面鼠标右键，选择Git Bash Here，在弹出的Git命令窗口中输入安装命令，然后回车。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><p>​&emsp;&emsp;选择一个盘创建一个文件夹，在新建的文件夹内鼠标右键，选择Git Bash Here，输入初始化命令，然后回车，等命令执行完，就会看到生成了一系列的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;接着在该文件夹中继续执行以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;命令执行完后浏览器访问<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000</a> 或者 127.0.0.1:4000 ,就会看到hexo的初始界面，是不是有着一丝丝的成就感？但是，这个界面还是在本地，别人并不能看到，想要别人看到，我们就必须将这些文件部署到Github上去。</p><p>&emsp;&emsp;前面我们已经在github上创建好了博客仓库，接下来我们编辑博客文件夹下的<strong>_config.yml</strong>文件，在文件最后找到关键字<strong>deploy</strong>，对其进行编辑，其中<strong>repo</strong>后面的值要改成你的仓库地址，注意键值对之间要有空格。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy: </span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/ocean233/ocean233.github.io</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;保存修改后，如果前面你的git已经可以推送文件到github上的话，你就可以直接执行以下命令将你的博客部署到GitHub上面。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;但是输入hexo d可能会报ERROR Deployer not fount： git错误，这是因为没有安装hexo-deployer-git这个模块，导致Git不能识别该命令，输入下面指令安装该模块即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;安装该模块会有些慢，因为Github毕竟是国外的网站，并不是很稳定，所以大家要耐心等待。安装失败时的话大家多试两遍。等模块安装完再次执行<strong>hexo d</strong>，这时就会有弹出框，输入自己之前注册的github账号进行登录，然后命令行也会要你输入对应的用户名并弹出输入框让你输入密码，填写完毕敲回车即可正确部署。</p><p>&emsp;&emsp;在浏览器输入<strong>你的用户名.github.io</strong>即可看到你自己搭建的博客了哦，如果上面的步骤都没问题，但是没有看到博客的话，可能是有些延迟，大家等等就好。</p><h2 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h2><p>&emsp;&emsp;搭建好的博客还很简单，博客样式说实话也是有点丑的，后面我们可以更换博客的主题，让博客更有特色。现在我们先来修改一下博客的基本配置吧。</p><p>&emsp;&emsp;对博客的配置修改主要是对配置文件<strong>_config.yml</strong>进行修改，我们现在的博客还很简单，所以能做的配置并不多，大家可以参考官网上的一些配置信息<a href="https://hexo.io/zh-cn/docs/configuration" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/configuration</a> ，我也会列几个主要配置供大家参考。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: Ocean&apos;s blog</span><br><span class="line">subtitle: 我的目标是星辰大海</span><br><span class="line">description: 大数据技术博客</span><br><span class="line">keywords:</span><br><span class="line">author: Ocean</span><br><span class="line">language: zh-CN</span><br><span class="line">timezone:</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这里大家可以修改博客的标题信息等，这是大家对博客进行定制化的第一步。</p><h2 id="编写文章"><a href="#编写文章" class="headerlink" title="编写文章"></a>编写文章</h2><p>&emsp;&emsp;我们搭建博客的主要目的自然是为了向大家分享我们的博客内容，绝对不是为了装B，所以如何写一篇文章才是我们应该关注的重点。</p><p>&emsp;&emsp;在你的博客文件夹目录下鼠标右键，点击Git Bash Here，接下来命令敲起来，新建一篇文章。如果没有设置 layout 的话，默认使用<strong>_config.yml</strong>中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new [layout] &lt;title&gt;</span><br><span class="line">$ hexo new &quot;post title with whitespace&quot;</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;这时候在/博客目录/source/posts目录下可以看到新建的博客文章，以.md结尾，在这里大家可以使用markdown语法编写自己的博客内容。</p><p><img src="https://i.loli.net/2019/04/28/5cc55d24c29d4.png" alt></p><p>&emsp;&emsp;博客内容写好后，回到命令行界面，敲命令将我们的博客内容部署到github上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;如果你想先看看编写的博客文章是怎样的，可以会用<strong>hexo s</strong>命令，在本地浏览器上先查看，没问题了再部署到github上。到这里，博客的基本操作你就已经熟悉了，可以开始玩转hexo了。</p>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
