{"meta":{"title":"Ocean's blog","subtitle":"我的目标是星辰大海","description":"大数据技术博客","author":"Ocean","url":"http://yoursite.com","root":"/"},"pages":[{"title":"分类","date":"2019-04-22T03:02:02.000Z","updated":"2019-04-25T09:46:49.947Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-04-22T03:23:47.000Z","updated":"2019-04-25T09:46:56.547Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"个人介绍","date":"2019-04-22T03:25:15.000Z","updated":"2019-04-28T11:04:41.938Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"&emsp;&emsp;博客诞生于2019年4月1号，博主是大数据开发工程师，请收下我的简历╭(●｀∀´●)╯╰(●’◡’●)╮ (●’◡’●)ﾉ ヾ(´▽‘)ﾉ： &emsp;&emsp;1.熟悉Hadoop生态体系及其架构原理，掌握Hadoop集群的搭建，并能用CDH快速部署Hadoop集群。&emsp;&emsp;2.熟悉HDFS的架构，掌握Yarn的任务执行流程。&emsp;&emsp;3.熟悉MapReduce的原理和流程，并能用其API进行开发，研究过MapReduce源码。&emsp;&emsp;4.熟悉Zookeeper的核心原理，并能应用其为集群提供协同服务，如hadoop的HA。&emsp;&emsp;5.熟练掌握Hive,清楚它的分区，分桶，索引，视图等机制;能够对其进行优化，并解决常见的数据倾斜问题，能够将hive 和 hbase 进行整合。&emsp;&emsp;6.熟练掌握Hbase,熟悉其架构原理，能够搭建hbase平台；熟练hbase的表设计和预分区，能够解决hbase的常见问题，如热点问题，懂得hbase二级索引设计，以及es+hbase的整合。&emsp;&emsp;7熟悉Spark的原理和流程，并能用Spark API开发应用程序；熟悉Spark Streaming，能用其开发准实时计算系统；熟悉SparkSQL，研究过Spark源码。&emsp;&emsp;8.熟悉Storm的原理和流程，并能使用API开发应用程序，熟悉Storm+Kafka实时流处理架构。&emsp;&emsp;9.熟悉常见的开源日志收集框架flume，Kafka消息队列，并能使用其实现不同场景的日志收集。&emsp;&emsp;10.掌握Nginx，掌握Redis缓存数据库应用，掌握Elasticsearch搜索引擎。&emsp;&emsp;11.理解机器学习的思想，熟悉机器学习常用算法，如逻辑回归，朴素贝叶斯，线性回归，Kmeans聚类，关联规则，随机森林等算法。&emsp;&emsp;12.熟练使用Linux常用的操作命令，掌握shell脚本编程。&emsp;&emsp;13.熟练使用Java、scala语言进行编程，能够使用Python语言进行脚本开发。"}],"posts":[{"title":"Zookeeper使用总结","slug":"Zookeeper使用总结","date":"2020-09-02T05:40:54.000Z","updated":"2020-09-02T05:58:27.003Z","comments":true,"path":"2020/09/02/Zookeeper使用总结/","link":"","permalink":"http://yoursite.com/2020/09/02/Zookeeper使用总结/","excerpt":"面试官：工作中使用过Zookeeper嘛？你知道它是什么，有什么用途呢？ 有使用过的，使用ZooKeeper作为dubbo的注册中心，使用ZooKeeper实现分布式锁。 ZooKeeper，它是一个开放源码的分布式协调服务，它是一个集群的管理者，它将简单易用的接口提供给用户。 可以基于Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 Zookeeper的用途：命名服务、配置管理、集群管理、分布式锁、队列管理 用途跟功能不是一个意思咩？给我一个眼神，让我自己体会","text":"面试官：工作中使用过Zookeeper嘛？你知道它是什么，有什么用途呢？ 有使用过的，使用ZooKeeper作为dubbo的注册中心，使用ZooKeeper实现分布式锁。 ZooKeeper，它是一个开放源码的分布式协调服务，它是一个集群的管理者，它将简单易用的接口提供给用户。 可以基于Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 Zookeeper的用途：命名服务、配置管理、集群管理、分布式锁、队列管理 用途跟功能不是一个意思咩？给我一个眼神，让我自己体会 面试官：说下什么是命名服务，什么是配置管理，又什么是集群管理吧 命名服务： 命名服务是指通过指定的名字来获取资源或者服务地址。Zookeeper可以创建一个全局唯一的路径，这个路径就可以作为一个名字。被命名的实体可以是集群中的机器，服务的地址，或者是远程的对象等。一些分布式服务框架（RPC、RMI）中的服务地址列表，通过使用命名服务，客户端应用能够根据特定的名字来获取资源的实体、服务地址和提供者信息等。举例来说，B服务部署在六台服务器上，存在六个完全不同的ip地址，同时B服务本身提供一个dubbo接口对外，此时有个A服务需要调用此接口，如果提供某一台服务器的ip，则存在该服务器宕机情况下接口不可用的情况，再切换ip就会影响服务的正常使用。此时，可以使用zookeeper作为注册中心，B服务的六台服务在指定znode下创建子节点，而A服务调用之前先通过指定znode的路径获取B服务的任意子节点中的ip信息，然后通过ip访问。同时zookeeper动态维护这部分节点，定时利用心跳请求检查B服务的服务器状态，一旦发现某服务器无反馈，就删除节点，防止被A服务获取调用 配置管理： ： 实际项目开发中，我们经常使用.properties或者xml需要配置很多信息，如数据库连接信息、fps地址端口等等。因为你的程序一般是分布式部署在不同的机器上（如果你是单机应用当我没说），如果把程序的这些配置信息保存在zk的znode节点下，当你要修改配置，即znode会发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。 集群管理 集群管理包括集群监控和集群控制，其实就是监控集群机器状态，剔除机器和加入机器。zookeeper可以方便集群机器的管理，它可以实时监控znode节点的变化，一旦发现有机器挂了，该机器就会与zk断开连接，对用的临时目录节点会被删除，其他所有机器都收到通知。新机器加入也是类似酱紫，所有机器收到通知：有新兄弟目录加入啦。 面试官：你提到了znode节点，那你知道znode有几种类型呢？zookeeper的数据模型是怎样的呢？zookeeper的数据模型 &emsp;&emsp;ZooKeeper的视图数据结构，很像Unix文件系统，也是树状的，这样可以确定每个路径都是唯一的。zookeeper的节点统一叫做znode，它是可以通过路径来标识，结构图如下： znode的4种类型 ​ &emsp;&emsp;根据节点的生命周期，znode可以分为4种类型，分别是持久节点（PERSISTENT）、持久顺序节点（PERSISTENT_SEQUENTIAL）、临时节点（EPHEMERAL）、临时顺序节点（EPHEMERAL_SEQUENTIAL） 持久节点（PERSISTENT） 这类节点被创建后，就会一直存在于Zk服务器上。直到手动删除。 持久顺序节点（PERSISTENT_SEQUENTIAL） 它的基本特性同持久节点，不同在于增加了顺序性。父节点会维护一个自增整性数字，用于子节点的创建的先后顺序。 临时节点（EPHEMERAL） 临时节点的生命周期与客户端的会话绑定，一旦客户端会话失效（非TCP连接断开），那么这个节点就会被自动清理掉。zk规定临时节点只能作为叶子节点。 临时顺序节点（EPHEMERAL_SEQUENTIAL） 基本特性同临时节点，添加了顺序的特性。 面试官：你知道znode节点里面存储的是什么吗？每个节点的数据最大不能超过多少呢？znode节点里面存储的是什么？ 123456public class DataNode implements Record &#123; byte data[]; Long acl; public StatPersisted stat; private Set&lt;String&gt; children = null; &#125; ​ &emsp;&emsp;哈哈，Znode包含了存储数据、访问权限、子节点引用、节点状态信息，如图： data: znode存储的业务数据信息 ACL: 记录客户端对znode节点的访问权限，如IP等。 child: 当前节点的子节点引用 stat: 包含Znode节点的状态信息，比如事务id、版本号、时间戳等等。 每个节点的数据最大不能超过多少呢 ​ &emsp;&emsp;为了保证高吞吐和低延迟，以及数据的一致性，znode只适合存储非常小的数据，不能超过1M，最好都小于1K。 面试官：你知道znode节点上的监听机制嘛？讲下Zookeeper watch机制吧。Watcher监听机制 ​ &emsp;&emsp;Zookeeper 允许客户端向服务端的某个Znode注册一个Watcher监听，当服务端的一些指定事件触发了这个Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 Watcher通知状态和事件类型做出业务上的改变。 可以把Watcher理解成客户端注册在某个Znode上的触发器，当这个Znode节点发生变化时（增删改查），就会触发Znode对应的注册事件，注册的客户端就会收到异步通知，然后做出业务的改变。 Watcher监听机制的工作原理 ZooKeeper的Watcher机制主要包括客户端线程、客户端 WatcherManager、Zookeeper服务器三部分。 客户端向ZooKeeper服务器注册Watcher的同时，会将Watcher对象存储在客户端的WatchManager中。 当zookeeper服务器触发watcher事件后，会向客户端发送通知， 客户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑。 Watcher特性总结 一次性：一个Watch事件是一个一次性的触发器。一次性触发，客户端只会收到一次这样的信息。 异步的: Zookeeper服务器发送watcher的通知事件到客户端是异步的，不能期望能够监控到节点每次的变化，Zookeeper只能保证最终的一致性，而无法保证强一致性。 轻量级： Watcher 通知非常简单，它只是通知发生了事件，而不会传递事件对象内容。 客户端串行： 执行客户端 Watcher 回调的过程是一个串行同步的过程。 注册 watcher用getData、exists、getChildren方法 触发 watcher用create、delete、setData方法 面试官：你对Zookeeper的数据结构都有一定了解，那你讲下Zookeeper的特性吧Zookeeper 保证了如下分布式一致性特性： 顺序一致性：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一视图：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性： 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来。 实时性（最终一致性）： Zookeeper 仅仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。 面试官：你刚提到顺序一致性，那zookeeper是如何保证事务的顺序一致性的呢？这道题可以看下这篇文章（本题答案来自该文章）：聊一聊ZooKeeper的顺序一致性 需要了解事务ID，即zxid。ZooKeeper的在选举时通过比较各结点的zxid和机器ID选出新的主结点的。zxid由Leader节点生成，有新写入事件时，Leader生成新zxid并随提案一起广播，每个结点本地都保存了当前最近一次事务的zxid，zxid是递增的，所以谁的zxid越大，就表示谁的数据是最新的。 ZXID的生成规则如下： ZXID有两部分组成： 任期：完成本次选举后，直到下次选举前，由同一Leader负责协调写入； 事务计数器：单调递增，每生效一次写入，计数器加一。 ZXID的低32位是计数器，所以同一任期内，ZXID是连续的，每个结点又都保存着自身最新生效的ZXID，通过对比新提案的ZXID与自身最新ZXID是否相差“1”，来保证事务严格按照顺序生效的。 面试官：你提到了Leader，你知道Zookeeper的服务器有几种角色嘛？Zookeeper下Server工作状态又有几种呢？Zookeeper集群中，有Leader、Follower和Observer三种角色 Leader Leader服务器是整个ZooKeeper集群工作机制中的核心，其主要工作： 事务请求的唯一调度和处理者，保证集群事务处理的顺序性 集群内部各服务的调度者 Follower Follower服务器是ZooKeeper集群状态的跟随者，其主要工作： 处理客户端非事务请求，转发事务请求给Leader服务器 参与事务请求Proposal的投票 参与Leader选举投票 Observer Observer是3.3.0 版本开始引入的一个服务器角色，它充当一个观察者角色——观察ZooKeeper集群的最新状态变化并将这些状态变更同步过来。其工作： 处理客户端的非事务请求，转发事务请求给 Leader 服务器 不参与任何形式的投票 Zookeeper下Server工作状态 服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、OBSERVING。 1.LOOKING：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。 2.FOLLOWING：跟随者状态。表明当前服务器角色是Follower。 3.LEADING：领导者状态。表明当前服务器角色是Leader。 4.OBSERVING：观察者状态。表明当前服务器角色是Observer。 面试官：你说到服务器角色是基于ZooKeeper集群的，那你画一下ZooKeeper集群部署图吧？ZooKeeper是如何保证主从节点数据一致性的呢？ZooKeeper集群部署图 ZooKeeper集群是一主多从的结构： 如果是写入数据，先写入主服务器（主节点），再通知从服务器。 如果是读取数据，既读主服务器的，也可以读从服务器的。 ZooKeeper如何保证主从节点数据一致性 &emsp;&emsp;我们知道集群是主从部署结构，要保证主从节点一致性问题，无非就是两个主要问题： 主服务器挂了，或者重启了 主从服务器之间同步数据~ &emsp;&emsp;Zookeeper是采用ZAB协议（Zookeeper Atomic Broadcast，Zookeeper原子广播协议）来保证主从节点数据一致性的，ZAB协议支持崩溃恢复和消息广播两种模式，很好解决了这两个问题： 崩溃恢复：Leader挂了，进入该模式，选一个新的leader出来 消息广播： 把更新的数据，从Leader同步到所有Follower Leader服务器挂了，所有集群中的服务器进入LOOKING状态，首先，它们会选举产生新的Leader服务器；接着，新的Leader服务器与集群中Follower服务进行数据同步，当集群中超过半数机器与该 Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式。Leader 服务器开始接收客户端的事务请求生成事务Proposal进行事务请求处理。 面试官：Leader挂了，进入崩溃恢复，是如何选举Leader的呢？你讲一下ZooKeeper选举机制吧服务器启动的Leader选举 zookeeper集群初始化阶段，服务器（myid=1-5）依次启动，开始zookeeper选举Leader~ 服务器1（myid=1）启动，当前只有一台服务器，无法完成Leader选举 服务器2（myid=2）启动，此时两台服务器能够相互通讯，开始进入Leader选举阶段 每个服务器发出一个投票 服务器1 和 服务器2都将自己作为Leader服务器进行投票，投票的基本元素包括：服务器的myid和ZXID，我们以（myid，ZXID）形式表示。初始阶段，服务器1和服务器2都会投给自己，即服务器1的投票为（1,0），服务器2的投票为（2,0），然后各自将这个投票发给集群中的其他所有机器。 接受来自各个服务器的投票 每个服务器都会接受来自其他服务器的投票。同时，服务器会校验投票的有效性，是否本轮投票、是否来自LOOKING状态的服务器。 处理投票 收到其他服务器的投票，会将被人的投票跟自己的投票PK，PK规则如下： 优先检查ZXID。ZXID比较大的服务器优先作为leader。 如果ZXID相同的话，就比较myid，myid比较大的服务器作为leader。 服务器1的投票是（1,0），它收到投票是（2,0），两者zxid都是0，因为收到的myid=2，大于自己的myid=1，所以它更新自己的投票为（2,0），然后重新将投票发出去。对于服务器2呢，即不再需要更新自己的投票，把上一次的投票信息发出即可。 统计投票 每次投票后，服务器会统计所有投票，判断是否有过半的机器接受到相同的投票信息。服务器2收到两票，少于3（n/2+1,n为总服务器），所以继续保持LOOKING状态 服务器3（myid=3）启动，继续进入Leader选举阶段 跟前面流程一致，服务器1和2先投自己一票，因为服务器3的myid最大，所以大家把票改投给它。此时，服务器为3票（大于等于n/2+1）,所以服务器3当选为Leader。 服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING； 服务器4启动，发起一次选举。 此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。选票信息结果：服务器3为4票，服务器4为1票。服务器4并更改状态为FOLLOWING； 服务器5启动，发起一次选举。 同理，服务器也是把票投给服务器3，服务器5并更改状态为FOLLOWING； 投票结束，服务器3当选为Leader 服务器运行期间的Leader选举 zookeeper集群的五台服务器（myid=1-5）正在运行中，突然某个瞬间，Leader服务器3挂了，这时候便开始Leader选举~ 1.变更状态 Leader 服务器挂了之后，余下的非Observer服务器都会把自己的服务器状态更改为LOOKING，然后开始进入Leader选举流程。 2.每个服务器发起投票 每个服务器都把票投给自己，因为是运行期间，所以每台服务器的ZXID可能不相同。假设服务1,2,4,5的zxid分别为333,666,999,888，则分别产生投票（1,333），（2，666），（4,999）和（5,888），然后各自将这个投票发给集群中的其他所有机器。 3.接受来自各个服务器的投票 4.处理投票 投票规则是跟Zookeeper集群启动期间一致的，优先检查ZXID，大的优先作为Leader，所以显然服务器zxid=999具有优先权。 5.统计投票 6.改变服务器状态 面试官： 你前面提到在项目中使用过Zookeeper的分布式锁，讲一下zk分布式锁的实现原理吧？Zookeeper就是使用临时顺序节点特性实现分布式锁的。 获取锁过程 （创建临时节点，检查序号最小） 释放锁 （删除临时节点，监听通知） 获取锁过程 当第一个客户端请求过来时，Zookeeper客户端会创建一个持久节点/locks。如果它（Client1）想获得锁，需要在locks节点下创建一个顺序节点lock1.如图 接着，客户端Client1会查找locks下面的所有临时顺序子节点，判断自己的节点lock1是不是排序最小的那一个，如果是，则成功获得锁。 这时候如果又来一个客户端client2前来尝试获得锁，它会在locks下再创建一个临时节点lock2 客户端client2一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock2是不是最小的，此时，发现lock1才是最小的，于是获取锁失败。获取锁失败，它是不会甘心的，client2向它排序靠前的节点lock1注册Watcher事件，用来监听lock1是否存在，也就是说client2抢锁失败进入等待状态。 此时，如果再来一个客户端Client3来尝试获取锁，它会在locks下再创建一个临时节点lock3 同样的，client3一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock3是不是最小的，发现自己不是最小的，就获取锁失败。它也是不会甘心的，它会向在它前面的节点lock2注册Watcher事件，以监听lock2节点是否存在。 释放锁 我们再来看看释放锁的流程，zookeeper的客户端业务完成或者故障，都会删除临时节点，释放锁。如果是任务完成，Client1会显式调用删除lock1的指令 如果是客户端故障了，根据临时节点得特性，lock1是会自动删除的 lock1节点被删除后，Client2可开心了，因为它一直监听着lock1。lock1节点删除，Client2立刻收到通知，也会查找locks下面的所有临时顺序子节点，发下lock2是最小，就获得锁。 同理，Client2获得锁之后，Client3也对它虎视眈眈，啊哈哈~ 面试官：好的，最后一道题，你说说dubbo和Zookeeper的关系吧，为什么选择Zookeeper作为注册中心？dubbo的注册中心可以选Zookeeper，memcached，redis等。为什么选择Zookeeper，因为它的功能特性咯~ 命名服务，服务提供者向Zookeeper指定节点写入url，完成服务发布。 负载均衡，注册中心的承载能力有限，而Zookeeper集群配合web应用很容易达到负载均衡。 zk支持监听事件，特别适合发布/订阅的场景，dubbo的生产者和消费者就类似这场景。 数据模型简单，数据存在内存，可谓高性能 Zookeeper其他特点都可以搬出来讲一下~","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yoursite.com/tags/Zookeeper/"}]},{"title":"Zookeeper使用实例——服务节点管理","slug":"Zookeeper使用实例——服务节点管理","date":"2020-08-30T07:46:21.000Z","updated":"2020-09-02T05:14:33.948Z","comments":true,"path":"2020/08/30/Zookeeper使用实例——服务节点管理/","link":"","permalink":"http://yoursite.com/2020/08/30/Zookeeper使用实例——服务节点管理/","excerpt":"&emsp;&emsp;分布式处理中，总会存在多个服务节点同时工作，并且节点数量会随着网络规模的变化而动态增减，服务节点也有可能发生宕机与恢复。面对着动态增减的服务节点，我们如何保证客户请求被服务器正确处理呢。我们可以通过zookeeper临时节点创建与自动删除来掌握服务节点的动态增减。","text":"&emsp;&emsp;分布式处理中，总会存在多个服务节点同时工作，并且节点数量会随着网络规模的变化而动态增减，服务节点也有可能发生宕机与恢复。面对着动态增减的服务节点，我们如何保证客户请求被服务器正确处理呢。我们可以通过zookeeper临时节点创建与自动删除来掌握服务节点的动态增减。 ​&emsp;&emsp;ignite分布式缓存支持使用zookeeper发现ignite节点的增减，这正是zookeeper管理服务节点的一个典型应用场景。我们来看看关键代码 12345678910// 关键方法，创建包含自增长id名称的目录，这个方法支持了分布式锁的实现// 四个参数：// 1、目录名称 2、目录文本信息 // 3、文件夹权限，Ids.OPEN_ACL_UNSAFE表示所有权限 // 4、目录类型，CreateMode.EPHEMERAL_SEQUENTIAL表示创建临时目录，session断开连接则目录自动删除String createdPath = zk.create( \"/\" + clusterNode + \"/\" + serverNode, address.getBytes(\"utf-8\"), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); ​&emsp;&emsp;采用CreateMode.EPHEMERAL_SEQUENTIAL模式创建临时节点，可以支持服务节点的实时管理。没错，这个模式和《Zookeeper使用实例——分布式共享锁》中创建有序节点支持分布式共享锁是一致的。EPHEMERAL_SEQUENTIAL表示创建有序的临时目录节点，zookeeper客户端创建临时节点后，只要session断开，该临时节点会自动删除。 ​&emsp;&emsp;所以，服务器在zookeeper上创建一个临时目录节点，通过节点事件监听我们可以知道服务器已经加入到服务网络中，监听到临时目录节点删除事件，我们可以知道该节点对应的服务器已经脱离服务网络。下面我们看看具体代码 服务器启动后在zookeeper创建临时目录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.coshaho.learn.zookeeper;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooDefs.Ids;import org.apache.zookeeper.ZooKeeper;/** * * 服务节点启动后注册到zookeeper * @author coshaho * */public class AppServer extends Thread&#123; private String clusterNode = \"Locks\"; private String serverNode = \"mylock\"; private String serverName; private long sleepTime; public void run() &#123; try &#123; connectZookeeper(serverName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void connectZookeeper(String address) throws Exception &#123; ZooKeeper zk = new ZooKeeper(\"192.168.1.104:12181\", 5000, new Watcher() &#123; public void process(WatchedEvent event) &#123;&#125; &#125;); // 关键方法，创建包含自增长id名称的目录，这个方法支持了分布式锁的实现 // 四个参数： // 1、目录名称 2、目录文本信息 // 3、文件夹权限，Ids.OPEN_ACL_UNSAFE表示所有权限 // 4、目录类型，CreateMode.EPHEMERAL_SEQUENTIAL表示创建临时目录，session断开连接则目录自动删除 String createdPath = zk.create( \"/\" + clusterNode + \"/\" + serverNode, address.getBytes(\"utf-8\"), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); System.out.println(\"create: \" + createdPath); Thread.sleep(sleepTime); &#125; public AppServer(String serverName, long sleepTime) &#123; this.serverName = serverName; this.sleepTime = sleepTime; &#125;&#125; 节点管理服务监听zookeeper临时目录节点创建删除事件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.coshaho.learn.zookeeper;import java.util.ArrayList;import java.util.List;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.Watcher.Event.EventType;import org.apache.zookeeper.ZooKeeper;/** * * 客户端注册监听server节点变化 * @author coshaho * */public class AppMaster &#123; private String clusterNode = \"Locks\"; private ZooKeeper zk; private volatile List&lt;String&gt; serverList; public void connectZookeeper() throws Exception &#123; // 注册全局默认watcher zk = new ZooKeeper(\"192.168.1.104:12181\", 5000, new Watcher() &#123; public void process(WatchedEvent event) &#123; /** * 有以下几种事件 * None * NodeCreated 节点被创建 * NodeDeleted 节点被删除 * NodeDataChanged 节点数据更新 * NodeChildrenChanged 子节点变更 */ if (event.getType() == EventType.NodeChildrenChanged &amp;&amp; (\"/\" + clusterNode).equals(event.getPath())) &#123; try &#123; updateServerList(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); updateServerList(); &#125; private void updateServerList() throws Exception &#123; List&lt;String&gt; newServerList = new ArrayList&lt;String&gt;(); // watcher注册后，只能监听事件一次，参数true表示继续使用默认watcher监听事件 List&lt;String&gt; subList = zk.getChildren(\"/\" + clusterNode, true); for (String subNode : subList) &#123; // 获取节点数据 byte[] data = zk.getData(\"/\" + clusterNode + \"/\" + subNode, false, null); newServerList.add(new String(data, \"utf-8\")); &#125; serverList = newServerList; System.out.println(\"server list updated: \" + serverList); &#125; public static void main(String[] args) throws Exception &#123; AppMaster ac = new AppMaster(); ac.connectZookeeper(); Thread.sleep(Long.MAX_VALUE); &#125;&#125; 启动两个服务器123456789101112131415161718192021package com.coshaho.learn.zookeeper;public class Server1 &#123; public static void main(String[] args) throws Exception &#123; AppServer server1 = new AppServer(\"Server1\", 5000); server1.start(); &#125;&#125;package com.coshaho.learn.zookeeper;public class Server2 &#123; public static void main(String[] args) throws Exception &#123; AppServer server1 = new AppServer(\"Server2\", 10000); server1.start(); &#125;&#125; 运行结果12345678log4j:WARN No appenders could be found for logger (org.apache.zookeeper.ZooKeeper).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.server list updated: []server list updated: [Server1]server list updated: [Server2, Server1]server list updated: [Server2]server list updated: []","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yoursite.com/tags/Zookeeper/"}]},{"title":"Flink Table 的三种 Sink 模式","slug":"Flink-Table-的三种-Sink-模式","date":"2020-08-09T09:13:45.000Z","updated":"2020-08-10T02:01:46.397Z","comments":true,"path":"2020/08/09/Flink-Table-的三种-Sink-模式/","link":"","permalink":"http://yoursite.com/2020/08/09/Flink-Table-的三种-Sink-模式/","excerpt":"Flink简介&emsp;&emsp;作为计算引擎 Flink 应用的计算结果总要以某种方式输出，比如调试阶段的打印到控制台或者生产阶段的写到数据库。而对于本来就需要在 Flink 内存保存中间及最终计算结果的应用来说，比如进行聚合统计的应用，输出结果便是将内存中的结果同步到外部。就 Flink Table/SQL API 而言，这里的同步会有三种模式，分别是 Append、Upsert 和 Retract。实际上这些输出计算结果的模式并不限于某个计算框架，比如 Storm、Spark 或者 Flink DataStream 都可以应用这些模式，不过 Flink Table/SQL 已有完整的概念和内置实现，更方便讨论。","text":"Flink简介&emsp;&emsp;作为计算引擎 Flink 应用的计算结果总要以某种方式输出，比如调试阶段的打印到控制台或者生产阶段的写到数据库。而对于本来就需要在 Flink 内存保存中间及最终计算结果的应用来说，比如进行聚合统计的应用，输出结果便是将内存中的结果同步到外部。就 Flink Table/SQL API 而言，这里的同步会有三种模式，分别是 Append、Upsert 和 Retract。实际上这些输出计算结果的模式并不限于某个计算框架，比如 Storm、Spark 或者 Flink DataStream 都可以应用这些模式，不过 Flink Table/SQL 已有完整的概念和内置实现，更方便讨论。 基础原理&emsp;&emsp;相信接触过 Streaming SQL 的同学都有了解或者听过流表二象性，简单来说流和表是同一事实的不同表现，是可以相互转换的。流和表的表述在业界不尽相同，笔者比较喜欢的一种是: 流体现事实在时间维度上的变化，而表则体现事实在某个时间点的视图。如果将流比作水管中流动的水，那么表将是杯子里静止的水。 &emsp;&emsp;将流转换为表的方法对于大多数读者都不陌生，只需将聚合统计函数应用到流上，流很自然就变为表（值得注意的是，Flink 的 Dynamic Table 和表的定义有细微不同，这将在下文讲述）。比如对于一个计算 PV 的简单流计算作业，将用户浏览日志数据流安 url 分类统计，变成 (url, views) 这样的一个表。然而对于如何将表转换成流，读者则未必有这么清晰的概念。 &emsp;&emsp;假设一个典型的实时流计算应用的工作流程可以被简化为下图: &emsp;&emsp;其中很关键的一点是 Transformation 是否聚合类型的计算。若否，则输出结果依然是流，可以很自然地使用原本流处理的 Sink（与外部系统的连接器）；若是，则流会转换为表，那么输出的结果将是表，而一个表的输出通常是批处理的概念，不能直接简单地用流处理的 Sink 来表达。 &emsp;&emsp;这时有个很朴素的想法是，我们能不能避免批处理那种全量的输出，每次只输出表的 diff，也就是 changelog。这也是表转化为流的方法: 持续观察表的变化，并将每个变化记录成日志输出。因此，流和表的转换可以以下图表示: &emsp;&emsp;其中表的变化具体可以分为 INSERT、UPDATE 和 DELETE 三类，而 Flink 根据这些变化类型分别总结了三种结果的输出模式。 模式 INSERT UPDATE DELETE Append 支持 不支持 不支持 Upsert 支持 支持 支持 Retract 支持 支持 支持 &emsp;&emsp;通常来说 Append 是最容易实现但功能最弱的，Retract 是最难实现而功能最强的。下文分别谈谈三种模式的特点和应用场景。 Append 输出模式&emsp;&emsp;Append 是最为简单的输出模式，只支持追加结果记录的操作。因为结果一旦输出以后便不会再有变更，Append 输出模式的最大特性是不可变性（immutability），而不可变性最令人向往的优势便是安全，比如线程安全或者 Event Sourcing 的可恢复性，不过同时也会给业务操作带来限制。通常来说，Append 模式会用于写入不方便做撤回或者删除操作的存储系统的场景，比如 Kafka 等 MQ 或者打印到控制台。 &emsp;&emsp;在实时聚合统计中，聚合统计的结果输出是由 Trigger 决定的，而 Append-Only 则意味着对于每个窗口实例（Pane，窗格）Trigger 只能触发一次，则就导致无法在迟到数据到达时再刷新结果。通常来说，我们可以给 Watermark 设置一个较大的延迟容忍阈值来避免这种刷新（再有迟到数据则丢弃），但代价是却会引入较大的延迟。 &emsp;&emsp;不过对于不涉及聚合的 Table 来说，Append 输出模式是非常好用的，因为这类 Table 只是将数据流的记录按时间顺序排在一起，每条记录间的计算都是独立的。值得注意的是，从 DataFlow Model 的角度来看未做聚合操作的流不应当称为表，但是在 Flink 的概念里所有的流都可以称为 Dynamic Table。笔者认为这个设计也有一定的道理，原因是从流中截取一段出来依然可以满足表的定义，即”某个时间点的视图”，而且我们可以争辩说不聚合也是一种聚合函数。 Upsert 输出模式&emsp;&emsp;Upsert 是 Append 模式的升级版，支持 Append-Only 的操作和在有主键的前提下的 UPDATE 和 DELETE 操作。Upsert 模式依赖业务主键来实现输出结果的更新和删除，因此非常适合 KV 数据库，比如HBase、JDBC 的 TableSink 都使用了这种方式。 &emsp;&emsp;在底层，Upsert 模式下的结果更新会被翻译为 (Boolean, ROW) 的二元组。其中第一个元素表示操作类型，true 对应 UPSERT 操作（不存在该元素则 INSERT，存在则 UPDATE），false 对应 DELETE 操作，第二个元素则是操作对应的记录。如果结果表本身是 Append-Only 的，第一个元素会全部为 true，而且也无需提供业务主键。 &emsp;&emsp;Upsert 模式是目前来说比较实用的模式，因为大部分业务都会提供原子或复合类型的主键，而在支持 KV 的存储系统也非常多，但要注意的是不要变更主键，具体原因会在下一节谈到。 Retract 输出模式&emsp;&emsp;Retract 是三种输出模式中功能最强大但实现也最复杂的一种，它要求目标存储系统可以追踪每个条记录，而且这些记录至少在一定时间内都是可以撤回的，因此通常来说它会自带系统主键，不必依赖于业务主键。然而由于大数据存储系统很少有可以精确到一条记录的更新操作，因此目前来说至少在 Flink 原生的 TableSink 中还没有能在生产环境中满足这个要求的。 &emsp;&emsp;不同于 Upsert 模式更新时会将整条记录重新输出，Retract 模式会将更新分成两条表示增减量的消息，一条是 (false, OldRow) 的撤回（Retract）操作，一条是 (true, NewRow) 的积累（Accumulate）操作。这样的好处是，在主键出现变化的情况下，Upsert 输出模式无法撤回旧主键的记录，导致数据不准确，而 Retract 模式则不存在这个问题。 &emsp;&emsp;举个例子，假设我们将电商订单按照承运快递公司进行分类计数，有如下的结果表。 公司 订单数 中通 2 圆通 1 顺丰 3 &emsp;&emsp;那么如果原本一单为中通的快递，后续更新为用顺丰发货，对于 Upsert 模式会产生 (true, (顺丰, 4)) 这样一条 changelog，但中通的订单数没有被修正。相比之下，Retract 模式产出 (false, (中通, 1)) 和 (true, (顺丰, 1)) 两条数据，则可以正确地更新数据。 总结&emsp;&emsp;Flink Table Sink 的三种模式本质上是如何监控结果表并产生 changelog，这可以应用于所有需要将表转为流的场景，包括同一个 Flink 应用的不同表间的联动。三种模式中 Append 模式只支持表的 INSERT，最为简单；Upsert 模式依赖业务主键提供 INSERT、UPDATE 和 DELETE 全部三类变更，比较实用；Retract 模式同样支持三类变更且不要求业务主键，但会将 UPDATE 翻译为旧数据的撤回和新数据的累加，实现上比较复杂。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"Flink","slug":"Flink","permalink":"http://yoursite.com/tags/Flink/"}]},{"title":"Linux常用命令","slug":"Linux常用命令","date":"2019-04-22T02:41:35.000Z","updated":"2019-04-26T03:32:06.379Z","comments":true,"path":"2019/04/22/Linux常用命令/","link":"","permalink":"http://yoursite.com/2019/04/22/Linux常用命令/","excerpt":"&emsp;&emsp;最近都在和Linux打交道，我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢Linux的原因，比较短小但却功能强大。","text":"&emsp;&emsp;最近都在和Linux打交道，我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢Linux的原因，比较短小但却功能强大。 文件目录1234567mkdir test 创建文件夹rm -rf /test 删除文件夹cd /test 切换文件夹pwd 查看文件夹路径cp -r test /root 拷贝文件夹目录mv test /root 移动文件夹、更改文件夹的名字ls ll 查看文件夹下文件 文件123456789touch test.txt 新建文件cp test.txt newtest.txt 复制文件rm -f test.txt 删除文件cat test.txt 查看文件内容more test.txt 分屏显示文件内容 空格键显示下一页内容，B键显示上一页内容，Q键退出head -10 test.txt 打印文件1-10行tail -10 test.txt 打印最后10行内容tail -f test.txt 实时打印文件内容find 路径 -name test.txt 查找文件或目录，列出路径，可以使用正则表达式查找 vi/vim123456789101112131415161718192021命令行模式 :w保存 :q退出 :q!不保存强制退出 :set nu显示行号 :/单词查找匹配 :N,Md 删除N-M行数据 一般模式： yy复制当前行 nyy复制下面n行 p粘贴到下一行 P粘贴到上一行 G移动到最后一行 nG移动到第n行 n+光标下移n行 n-光标上移n行 H光标移动到屏幕顶行 M光标移动到屏幕中间行 L光标移动到屏幕最后行 dd删除行 x删除光标后一个字符 X删除光标前一个字符 u恢复前一个动作 远程拷贝12scp [-r] test.txt root@node02:`pwd` 本地到远程scp [-r] root@node02:/test /root/ 远程到本地 磁盘指令12df [-m][-k][-h] 查看硬盘信息du [-k][-m][-a][-h][-max-depth=0] /目录 查看目录信息 网络指令12345ifconfig 查看网络配置ping ip地址 查看是否连通netstat 查看网络相关信息telnet 192.168.198.111 22 测试远程主机网络端口 Ctrl+] 输入q退出curl -X GET http://www.baidu.com/ http请求模拟 ​ 系统配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859*用户操作指令： useradd ocean 添加用户，创建一个组 passwd ocean 修改密码 useradd -r ocean 删除用户 usermod -l newocean ocean 修改用户名 usermod -L ocean 锁定账号 usermod -U ocean 解锁账号 /etc/passwd /etc/shodow 查看用户*用户组操作指令： groupadd groupname创建用户组 groupdel groupname删除用户组 groupmod -n newname name 修改用户组名 groups 查看当前登录用户的组内成员 groups ocean 查看指定用户所在组 usermod [-g][-G] 组名 用户 修改用户的主组或者附加组 cat /etc/group 查看组*文件权限： UGO模型：USER GROUP OTHER chown -R user:group 目录名字 修改整个目录下的所有者和属组 chmod ugo+rwx test.txt 修改文件的权限 chmod 700 test.txt 设置权限*系统服务初始化配置： 0：停机状态 1：单用户模式 2：多用户 3：完全多用户 4：为定义 5：图形化 6：停止所有进程，重启*系统时间指令： date 查看时间 date -s 时间 修改时间 时间同步： yum -y install ntp ntpdate cn.ntp.org.cn *配置主机名： vim /etc/sysconfig/network*配置域名映射： vim /etc/hosts*sudo权限配置： vim /etc/sudoers sudo -l*环境变量： vim /etc/profile 全局 echo $path 显示环境变量 source /etc/profile 重新加载环境变量 vi ~/.bash_profile 临时 *防火墙： service iptables status查看状态 chkconfig iptables on/off 永久生效 service iptables start 即时生效 重定向和管道123456789输出重定向：&gt; &gt;&gt;输入重定向：&lt; &lt;&lt;标准输出重定向： 1&gt;错误输出重定向： 2&gt;结合使用：2&gt;&amp;1管道： |命令执行控制：&amp;&amp; 前一个命令执行成功才会执行后一个命令 || 前一个命令执行失败才会执行后一个命令信息黑洞：/dev/null shell脚本123456789101112131415161718定义变量：name=&quot;ocean&quot;引用变量：$name数组：my_array=&#123;A,B,C,D&#125; $&#123;my_array[0]&#125;运算符： 表达式和运算符之间必须有空格 完整的表达式要被 ` ` 包含 val=`expr $a + $b` val=`expr $a - $b` val=`expr $a \\* $b` val=`expr $b / $a` val=`expr $b % $a` $a == $b $a != $b -eq是否相等 -ne是否不相等 -gt左边是否大于右边 -lt左边是否小于右边 -ge左边是大于等于右边 -le左边是否小于等于右边 &amp;&amp; || =字符串是否相等 !=是否不想等 -z长度是否为0 -n长度是否不为0 str是否为不为空 流程控制 函数test()&#123;&#125; 服务指令123456789101112列出所有服务 chkconfig service 服务名 start/stop/status/restart添加服务 /etc/init.d系统各种服务的启动和停止脚本 /etc/rc.d/ 系统对应执行级别的服务软连接步骤：在脚本中添加两行代码#chkconfig: 2345 80 90 #description:auto_run 编写脚本 修改可执行权限 将脚本拷贝到/etc/init.d目录下 加入到服务里chkconfig --add test.sh 重启服务器删除服务：chkconfig --del name服务等级更改：chkconfig --level 2345 name off|on 默认是2345 定时调度1234minute hour day month dayofweek 命令查看定时任务：/var/spool/mail 目录下放各用户定时任务，执行后的信息 /var/spool/cron 目录存放每个用户的定时任务 contab –l 可以直接查看当前用户的定时任务 linux安全1234selinux enforcing强制模式 permissive宽容模式 disabled关闭sestatus -v查看状态 linux进程123456ps -aux查看进程 jobs -lps -ef | grep ssh查看相关进程ps -aux --sort -pcpu根据CPU使用来升序排列top性能分析nohup /root/start.h &amp; 后台运行kill -9 杀死进程 解压压缩下载123456789yum下载wget下载RPM命令：rpm –ivh rpm包 安装 rpm -q ntp 查找 rpm –e 包名 卸载tar命令：tar -zvxf xxxx.tar.gz 解压 tar -zcf 压缩包命名 压缩目标 压缩zip命令：zip -r 包名 目标目录 压缩 unzip filename 解压 ​​​","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"hexo博客搭建","slug":"hexo博客搭建","date":"2019-04-16T07:25:46.000Z","updated":"2019-04-28T11:01:03.396Z","comments":true,"path":"2019/04/16/hexo博客搭建/","link":"","permalink":"http://yoursite.com/2019/04/16/hexo博客搭建/","excerpt":"简介&emsp;&emsp;最近一段时间比较闲，想着搭个博客玩玩，看了网上主流的博客网站，不是太喜欢，作为一个互联网行业的小渣渣，博客当然要自己搭才有意思了，于是在网上找了一些方案，最终选择了hexo+github的方式来搭建个人博客。","text":"简介&emsp;&emsp;最近一段时间比较闲，想着搭个博客玩玩，看了网上主流的博客网站，不是太喜欢，作为一个互联网行业的小渣渣，博客当然要自己搭才有意思了，于是在网上找了一些方案，最终选择了hexo+github的方式来搭建个人博客。 &emsp;&emsp;使用github pages服务搭建博客的好处有： 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台； 准备工作&emsp;&emsp;在你的博客之旅开始之前，首先要创建github账号，这个不做过多的介绍。登录你的github账户，创建一个名为你的用户名.github.io的仓库，将来你的博客访问地址就是这个啦。你也可以购买域名替换你的博客地址，当然这是要花钱的。 &emsp;&emsp;仓库建好后，我们需要在电脑上安装git和node.js，在这里要注意Git要提前配置好，和github做绑定，以后要用git工具将代码提交到github上保存的哦。node.js 因为整个博客框架是基于node.js的，所以必须安装node.js环境，安装过程中一路Next即可。 安装hexo框架&emsp;&emsp;准备工作做好后，我们就可以正式开始博客的搭建。Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。&emsp;&emsp;在桌面鼠标右键，选择Git Bash Here，在弹出的Git命令窗口中输入安装命令，然后回车。 1npm install -g hexo-cli ​&emsp;&emsp;选择一个盘创建一个文件夹，在新建的文件夹内鼠标右键，选择Git Bash Here，输入初始化命令，然后回车，等命令执行完，就会看到生成了一系列的文件。 12hexo initnpm install &emsp;&emsp;接着在该文件夹中继续执行以下命令 12hexo ghexo s &emsp;&emsp;命令执行完后浏览器访问http://localhost:4000 或者 127.0.0.1:4000 ,就会看到hexo的初始界面，是不是有着一丝丝的成就感？但是，这个界面还是在本地，别人并不能看到，想要别人看到，我们就必须将这些文件部署到Github上去。 &emsp;&emsp;前面我们已经在github上创建好了博客仓库，接下来我们编辑博客文件夹下的_config.yml文件，在文件最后找到关键字deploy，对其进行编辑，其中repo后面的值要改成你的仓库地址，注意键值对之间要有空格。 1234deploy: type: git repo: https://github.com/ocean233/ocean233.github.io branch: master &emsp;&emsp;保存修改后，如果前面你的git已经可以推送文件到github上的话，你就可以直接执行以下命令将你的博客部署到GitHub上面。 12hexo ghexo d &emsp;&emsp;但是输入hexo d可能会报ERROR Deployer not fount： git错误，这是因为没有安装hexo-deployer-git这个模块，导致Git不能识别该命令，输入下面指令安装该模块即可。 1npm install hexo-deployer-git --save &emsp;&emsp;安装该模块会有些慢，因为Github毕竟是国外的网站，并不是很稳定，所以大家要耐心等待。安装失败时的话大家多试两遍。等模块安装完再次执行hexo d，这时就会有弹出框，输入自己之前注册的github账号进行登录，然后命令行也会要你输入对应的用户名并弹出输入框让你输入密码，填写完毕敲回车即可正确部署。 &emsp;&emsp;在浏览器输入你的用户名.github.io即可看到你自己搭建的博客了哦，如果上面的步骤都没问题，但是没有看到博客的话，可能是有些延迟，大家等等就好。 基础配置&emsp;&emsp;搭建好的博客还很简单，博客样式说实话也是有点丑的，后面我们可以更换博客的主题，让博客更有特色。现在我们先来修改一下博客的基本配置吧。 &emsp;&emsp;对博客的配置修改主要是对配置文件_config.yml进行修改，我们现在的博客还很简单，所以能做的配置并不多，大家可以参考官网上的一些配置信息https://hexo.io/zh-cn/docs/configuration ，我也会列几个主要配置供大家参考。 12345678# Sitetitle: Ocean&apos;s blogsubtitle: 我的目标是星辰大海description: 大数据技术博客keywords:author: Oceanlanguage: zh-CNtimezone: &emsp;&emsp;这里大家可以修改博客的标题信息等，这是大家对博客进行定制化的第一步。 编写文章&emsp;&emsp;我们搭建博客的主要目的自然是为了向大家分享我们的博客内容，绝对不是为了装B，所以如何写一篇文章才是我们应该关注的重点。 &emsp;&emsp;在你的博客文件夹目录下鼠标右键，点击Git Bash Here，接下来命令敲起来，新建一篇文章。如果没有设置 layout 的话，默认使用_config.yml中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。12$ hexo new [layout] &lt;title&gt;$ hexo new &quot;post title with whitespace&quot; &emsp;&emsp;这时候在/博客目录/source/posts目录下可以看到新建的博客文章，以.md结尾，在这里大家可以使用markdown语法编写自己的博客内容。 &emsp;&emsp;博客内容写好后，回到命令行界面，敲命令将我们的博客内容部署到github上。12hexo ghexo d &emsp;&emsp;如果你想先看看编写的博客文章是怎样的，可以会用hexo s命令，在本地浏览器上先查看，没问题了再部署到github上。到这里，博客的基本操作你就已经熟悉了，可以开始玩转hexo了。","categories":[{"name":"博客","slug":"博客","permalink":"http://yoursite.com/categories/博客/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"博客","slug":"博客","permalink":"http://yoursite.com/tags/博客/"}]}]}