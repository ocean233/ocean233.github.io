{"meta":{"title":"Ocean's blog","subtitle":"我的目标是星辰大海","description":"大数据技术博客","author":"Ocean","url":"http://yoursite.com","root":"/"},"pages":[{"title":"个人介绍","date":"2019-04-22T03:25:15.000Z","updated":"2019-04-28T11:04:41.938Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"&emsp;&emsp;博客诞生于2019年4月1号，博主是大数据开发工程师，请收下我的简历╭(●｀∀´●)╯╰(●’◡’●)╮ (●’◡’●)ﾉ ヾ(´▽‘)ﾉ： &emsp;&emsp;1.熟悉Hadoop生态体系及其架构原理，掌握Hadoop集群的搭建，并能用CDH快速部署Hadoop集群。&emsp;&emsp;2.熟悉HDFS的架构，掌握Yarn的任务执行流程。&emsp;&emsp;3.熟悉MapReduce的原理和流程，并能用其API进行开发，研究过MapReduce源码。&emsp;&emsp;4.熟悉Zookeeper的核心原理，并能应用其为集群提供协同服务，如hadoop的HA。&emsp;&emsp;5.熟练掌握Hive,清楚它的分区，分桶，索引，视图等机制;能够对其进行优化，并解决常见的数据倾斜问题，能够将hive 和 hbase 进行整合。&emsp;&emsp;6.熟练掌握Hbase,熟悉其架构原理，能够搭建hbase平台；熟练hbase的表设计和预分区，能够解决hbase的常见问题，如热点问题，懂得hbase二级索引设计，以及es+hbase的整合。&emsp;&emsp;7熟悉Spark的原理和流程，并能用Spark API开发应用程序；熟悉Spark Streaming，能用其开发准实时计算系统；熟悉SparkSQL，研究过Spark源码。&emsp;&emsp;8.熟悉Storm的原理和流程，并能使用API开发应用程序，熟悉Storm+Kafka实时流处理架构。&emsp;&emsp;9.熟悉常见的开源日志收集框架flume，Kafka消息队列，并能使用其实现不同场景的日志收集。&emsp;&emsp;10.掌握Nginx，掌握Redis缓存数据库应用，掌握Elasticsearch搜索引擎。&emsp;&emsp;11.理解机器学习的思想，熟悉机器学习常用算法，如逻辑回归，朴素贝叶斯，线性回归，Kmeans聚类，关联规则，随机森林等算法。&emsp;&emsp;12.熟练使用Linux常用的操作命令，掌握shell脚本编程。&emsp;&emsp;13.熟练使用Java、scala语言进行编程，能够使用Python语言进行脚本开发。"},{"title":"标签","date":"2019-04-22T03:23:47.000Z","updated":"2019-04-25T09:46:56.547Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-04-22T03:02:02.000Z","updated":"2019-04-25T09:46:49.947Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Flink Table 的三种 Sink 模式","slug":"Flink-Table-的三种-Sink-模式","date":"2020-08-09T09:13:45.000Z","updated":"2020-08-10T02:01:46.397Z","comments":true,"path":"2020/08/09/Flink-Table-的三种-Sink-模式/","link":"","permalink":"http://yoursite.com/2020/08/09/Flink-Table-的三种-Sink-模式/","excerpt":"Flink简介&emsp;&emsp;作为计算引擎 Flink 应用的计算结果总要以某种方式输出，比如调试阶段的打印到控制台或者生产阶段的写到数据库。而对于本来就需要在 Flink 内存保存中间及最终计算结果的应用来说，比如进行聚合统计的应用，输出结果便是将内存中的结果同步到外部。就 Flink Table/SQL API 而言，这里的同步会有三种模式，分别是 Append、Upsert 和 Retract。实际上这些输出计算结果的模式并不限于某个计算框架，比如 Storm、Spark 或者 Flink DataStream 都可以应用这些模式，不过 Flink Table/SQL 已有完整的概念和内置实现，更方便讨论。","text":"Flink简介&emsp;&emsp;作为计算引擎 Flink 应用的计算结果总要以某种方式输出，比如调试阶段的打印到控制台或者生产阶段的写到数据库。而对于本来就需要在 Flink 内存保存中间及最终计算结果的应用来说，比如进行聚合统计的应用，输出结果便是将内存中的结果同步到外部。就 Flink Table/SQL API 而言，这里的同步会有三种模式，分别是 Append、Upsert 和 Retract。实际上这些输出计算结果的模式并不限于某个计算框架，比如 Storm、Spark 或者 Flink DataStream 都可以应用这些模式，不过 Flink Table/SQL 已有完整的概念和内置实现，更方便讨论。 基础原理&emsp;&emsp;相信接触过 Streaming SQL 的同学都有了解或者听过流表二象性，简单来说流和表是同一事实的不同表现，是可以相互转换的。流和表的表述在业界不尽相同，笔者比较喜欢的一种是: 流体现事实在时间维度上的变化，而表则体现事实在某个时间点的视图。如果将流比作水管中流动的水，那么表将是杯子里静止的水。 &emsp;&emsp;将流转换为表的方法对于大多数读者都不陌生，只需将聚合统计函数应用到流上，流很自然就变为表（值得注意的是，Flink 的 Dynamic Table 和表的定义有细微不同，这将在下文讲述）。比如对于一个计算 PV 的简单流计算作业，将用户浏览日志数据流安 url 分类统计，变成 (url, views) 这样的一个表。然而对于如何将表转换成流，读者则未必有这么清晰的概念。 &emsp;&emsp;假设一个典型的实时流计算应用的工作流程可以被简化为下图: &emsp;&emsp;其中很关键的一点是 Transformation 是否聚合类型的计算。若否，则输出结果依然是流，可以很自然地使用原本流处理的 Sink（与外部系统的连接器）；若是，则流会转换为表，那么输出的结果将是表，而一个表的输出通常是批处理的概念，不能直接简单地用流处理的 Sink 来表达。 &emsp;&emsp;这时有个很朴素的想法是，我们能不能避免批处理那种全量的输出，每次只输出表的 diff，也就是 changelog。这也是表转化为流的方法: 持续观察表的变化，并将每个变化记录成日志输出。因此，流和表的转换可以以下图表示: &emsp;&emsp;其中表的变化具体可以分为 INSERT、UPDATE 和 DELETE 三类，而 Flink 根据这些变化类型分别总结了三种结果的输出模式。 模式 INSERT UPDATE DELETE Append 支持 不支持 不支持 Upsert 支持 支持 支持 Retract 支持 支持 支持 &emsp;&emsp;通常来说 Append 是最容易实现但功能最弱的，Retract 是最难实现而功能最强的。下文分别谈谈三种模式的特点和应用场景。 Append 输出模式&emsp;&emsp;Append 是最为简单的输出模式，只支持追加结果记录的操作。因为结果一旦输出以后便不会再有变更，Append 输出模式的最大特性是不可变性（immutability），而不可变性最令人向往的优势便是安全，比如线程安全或者 Event Sourcing 的可恢复性，不过同时也会给业务操作带来限制。通常来说，Append 模式会用于写入不方便做撤回或者删除操作的存储系统的场景，比如 Kafka 等 MQ 或者打印到控制台。 &emsp;&emsp;在实时聚合统计中，聚合统计的结果输出是由 Trigger 决定的，而 Append-Only 则意味着对于每个窗口实例（Pane，窗格）Trigger 只能触发一次，则就导致无法在迟到数据到达时再刷新结果。通常来说，我们可以给 Watermark 设置一个较大的延迟容忍阈值来避免这种刷新（再有迟到数据则丢弃），但代价是却会引入较大的延迟。 &emsp;&emsp;不过对于不涉及聚合的 Table 来说，Append 输出模式是非常好用的，因为这类 Table 只是将数据流的记录按时间顺序排在一起，每条记录间的计算都是独立的。值得注意的是，从 DataFlow Model 的角度来看未做聚合操作的流不应当称为表，但是在 Flink 的概念里所有的流都可以称为 Dynamic Table。笔者认为这个设计也有一定的道理，原因是从流中截取一段出来依然可以满足表的定义，即”某个时间点的视图”，而且我们可以争辩说不聚合也是一种聚合函数。 Upsert 输出模式&emsp;&emsp;Upsert 是 Append 模式的升级版，支持 Append-Only 的操作和在有主键的前提下的 UPDATE 和 DELETE 操作。Upsert 模式依赖业务主键来实现输出结果的更新和删除，因此非常适合 KV 数据库，比如HBase、JDBC 的 TableSink 都使用了这种方式。 &emsp;&emsp;在底层，Upsert 模式下的结果更新会被翻译为 (Boolean, ROW) 的二元组。其中第一个元素表示操作类型，true 对应 UPSERT 操作（不存在该元素则 INSERT，存在则 UPDATE），false 对应 DELETE 操作，第二个元素则是操作对应的记录。如果结果表本身是 Append-Only 的，第一个元素会全部为 true，而且也无需提供业务主键。 &emsp;&emsp;Upsert 模式是目前来说比较实用的模式，因为大部分业务都会提供原子或复合类型的主键，而在支持 KV 的存储系统也非常多，但要注意的是不要变更主键，具体原因会在下一节谈到。 Retract 输出模式&emsp;&emsp;Retract 是三种输出模式中功能最强大但实现也最复杂的一种，它要求目标存储系统可以追踪每个条记录，而且这些记录至少在一定时间内都是可以撤回的，因此通常来说它会自带系统主键，不必依赖于业务主键。然而由于大数据存储系统很少有可以精确到一条记录的更新操作，因此目前来说至少在 Flink 原生的 TableSink 中还没有能在生产环境中满足这个要求的。 &emsp;&emsp;不同于 Upsert 模式更新时会将整条记录重新输出，Retract 模式会将更新分成两条表示增减量的消息，一条是 (false, OldRow) 的撤回（Retract）操作，一条是 (true, NewRow) 的积累（Accumulate）操作。这样的好处是，在主键出现变化的情况下，Upsert 输出模式无法撤回旧主键的记录，导致数据不准确，而 Retract 模式则不存在这个问题。 &emsp;&emsp;举个例子，假设我们将电商订单按照承运快递公司进行分类计数，有如下的结果表。 公司 订单数 中通 2 圆通 1 顺丰 3 &emsp;&emsp;那么如果原本一单为中通的快递，后续更新为用顺丰发货，对于 Upsert 模式会产生 (true, (顺丰, 4)) 这样一条 changelog，但中通的订单数没有被修正。相比之下，Retract 模式产出 (false, (中通, 1)) 和 (true, (顺丰, 1)) 两条数据，则可以正确地更新数据。 总结&emsp;&emsp;Flink Table Sink 的三种模式本质上是如何监控结果表并产生 changelog，这可以应用于所有需要将表转为流的场景，包括同一个 Flink 应用的不同表间的联动。三种模式中 Append 模式只支持表的 INSERT，最为简单；Upsert 模式依赖业务主键提供 INSERT、UPDATE 和 DELETE 全部三类变更，比较实用；Retract 模式同样支持三类变更且不要求业务主键，但会将 UPDATE 翻译为旧数据的撤回和新数据的累加，实现上比较复杂。","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"Flink","slug":"Flink","permalink":"http://yoursite.com/tags/Flink/"}]},{"title":"Linux常用命令","slug":"Linux常用命令","date":"2019-04-22T02:41:35.000Z","updated":"2019-04-26T03:32:06.379Z","comments":true,"path":"2019/04/22/Linux常用命令/","link":"","permalink":"http://yoursite.com/2019/04/22/Linux常用命令/","excerpt":"&emsp;&emsp;最近都在和Linux打交道，我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢Linux的原因，比较短小但却功能强大。","text":"&emsp;&emsp;最近都在和Linux打交道，我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢Linux的原因，比较短小但却功能强大。 文件目录1234567mkdir test 创建文件夹rm -rf /test 删除文件夹cd /test 切换文件夹pwd 查看文件夹路径cp -r test /root 拷贝文件夹目录mv test /root 移动文件夹、更改文件夹的名字ls ll 查看文件夹下文件 文件123456789touch test.txt 新建文件cp test.txt newtest.txt 复制文件rm -f test.txt 删除文件cat test.txt 查看文件内容more test.txt 分屏显示文件内容 空格键显示下一页内容，B键显示上一页内容，Q键退出head -10 test.txt 打印文件1-10行tail -10 test.txt 打印最后10行内容tail -f test.txt 实时打印文件内容find 路径 -name test.txt 查找文件或目录，列出路径，可以使用正则表达式查找 vi/vim123456789101112131415161718192021命令行模式 :w保存 :q退出 :q!不保存强制退出 :set nu显示行号 :/单词查找匹配 :N,Md 删除N-M行数据 一般模式： yy复制当前行 nyy复制下面n行 p粘贴到下一行 P粘贴到上一行 G移动到最后一行 nG移动到第n行 n+光标下移n行 n-光标上移n行 H光标移动到屏幕顶行 M光标移动到屏幕中间行 L光标移动到屏幕最后行 dd删除行 x删除光标后一个字符 X删除光标前一个字符 u恢复前一个动作 远程拷贝12scp [-r] test.txt root@node02:`pwd` 本地到远程scp [-r] root@node02:/test /root/ 远程到本地 磁盘指令12df [-m][-k][-h] 查看硬盘信息du [-k][-m][-a][-h][-max-depth=0] /目录 查看目录信息 网络指令12345ifconfig 查看网络配置ping ip地址 查看是否连通netstat 查看网络相关信息telnet 192.168.198.111 22 测试远程主机网络端口 Ctrl+] 输入q退出curl -X GET http://www.baidu.com/ http请求模拟 ​ 系统配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859*用户操作指令： useradd ocean 添加用户，创建一个组 passwd ocean 修改密码 useradd -r ocean 删除用户 usermod -l newocean ocean 修改用户名 usermod -L ocean 锁定账号 usermod -U ocean 解锁账号 /etc/passwd /etc/shodow 查看用户*用户组操作指令： groupadd groupname创建用户组 groupdel groupname删除用户组 groupmod -n newname name 修改用户组名 groups 查看当前登录用户的组内成员 groups ocean 查看指定用户所在组 usermod [-g][-G] 组名 用户 修改用户的主组或者附加组 cat /etc/group 查看组*文件权限： UGO模型：USER GROUP OTHER chown -R user:group 目录名字 修改整个目录下的所有者和属组 chmod ugo+rwx test.txt 修改文件的权限 chmod 700 test.txt 设置权限*系统服务初始化配置： 0：停机状态 1：单用户模式 2：多用户 3：完全多用户 4：为定义 5：图形化 6：停止所有进程，重启*系统时间指令： date 查看时间 date -s 时间 修改时间 时间同步： yum -y install ntp ntpdate cn.ntp.org.cn *配置主机名： vim /etc/sysconfig/network*配置域名映射： vim /etc/hosts*sudo权限配置： vim /etc/sudoers sudo -l*环境变量： vim /etc/profile 全局 echo $path 显示环境变量 source /etc/profile 重新加载环境变量 vi ~/.bash_profile 临时 *防火墙： service iptables status查看状态 chkconfig iptables on/off 永久生效 service iptables start 即时生效 重定向和管道123456789输出重定向：&gt; &gt;&gt;输入重定向：&lt; &lt;&lt;标准输出重定向： 1&gt;错误输出重定向： 2&gt;结合使用：2&gt;&amp;1管道： |命令执行控制：&amp;&amp; 前一个命令执行成功才会执行后一个命令 || 前一个命令执行失败才会执行后一个命令信息黑洞：/dev/null shell脚本123456789101112131415161718定义变量：name=&quot;ocean&quot;引用变量：$name数组：my_array=&#123;A,B,C,D&#125; $&#123;my_array[0]&#125;运算符： 表达式和运算符之间必须有空格 完整的表达式要被 ` ` 包含 val=`expr $a + $b` val=`expr $a - $b` val=`expr $a \\* $b` val=`expr $b / $a` val=`expr $b % $a` $a == $b $a != $b -eq是否相等 -ne是否不相等 -gt左边是否大于右边 -lt左边是否小于右边 -ge左边是大于等于右边 -le左边是否小于等于右边 &amp;&amp; || =字符串是否相等 !=是否不想等 -z长度是否为0 -n长度是否不为0 str是否为不为空 流程控制 函数test()&#123;&#125; 服务指令123456789101112列出所有服务 chkconfig service 服务名 start/stop/status/restart添加服务 /etc/init.d系统各种服务的启动和停止脚本 /etc/rc.d/ 系统对应执行级别的服务软连接步骤：在脚本中添加两行代码#chkconfig: 2345 80 90 #description:auto_run 编写脚本 修改可执行权限 将脚本拷贝到/etc/init.d目录下 加入到服务里chkconfig --add test.sh 重启服务器删除服务：chkconfig --del name服务等级更改：chkconfig --level 2345 name off|on 默认是2345 定时调度1234minute hour day month dayofweek 命令查看定时任务：/var/spool/mail 目录下放各用户定时任务，执行后的信息 /var/spool/cron 目录存放每个用户的定时任务 contab –l 可以直接查看当前用户的定时任务 linux安全1234selinux enforcing强制模式 permissive宽容模式 disabled关闭sestatus -v查看状态 linux进程123456ps -aux查看进程 jobs -lps -ef | grep ssh查看相关进程ps -aux --sort -pcpu根据CPU使用来升序排列top性能分析nohup /root/start.h &amp; 后台运行kill -9 杀死进程 解压压缩下载123456789yum下载wget下载RPM命令：rpm –ivh rpm包 安装 rpm -q ntp 查找 rpm –e 包名 卸载tar命令：tar -zvxf xxxx.tar.gz 解压 tar -zcf 压缩包命名 压缩目标 压缩zip命令：zip -r 包名 目标目录 压缩 unzip filename 解压 ​​​","categories":[{"name":"学习","slug":"学习","permalink":"http://yoursite.com/categories/学习/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"hexo博客搭建","slug":"hexo博客搭建","date":"2019-04-16T07:25:46.000Z","updated":"2019-04-28T11:01:03.396Z","comments":true,"path":"2019/04/16/hexo博客搭建/","link":"","permalink":"http://yoursite.com/2019/04/16/hexo博客搭建/","excerpt":"简介&emsp;&emsp;最近一段时间比较闲，想着搭个博客玩玩，看了网上主流的博客网站，不是太喜欢，作为一个互联网行业的小渣渣，博客当然要自己搭才有意思了，于是在网上找了一些方案，最终选择了hexo+github的方式来搭建个人博客。","text":"简介&emsp;&emsp;最近一段时间比较闲，想着搭个博客玩玩，看了网上主流的博客网站，不是太喜欢，作为一个互联网行业的小渣渣，博客当然要自己搭才有意思了，于是在网上找了一些方案，最终选择了hexo+github的方式来搭建个人博客。 &emsp;&emsp;使用github pages服务搭建博客的好处有： 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台； 准备工作&emsp;&emsp;在你的博客之旅开始之前，首先要创建github账号，这个不做过多的介绍。登录你的github账户，创建一个名为你的用户名.github.io的仓库，将来你的博客访问地址就是这个啦。你也可以购买域名替换你的博客地址，当然这是要花钱的。 &emsp;&emsp;仓库建好后，我们需要在电脑上安装git和node.js，在这里要注意Git要提前配置好，和github做绑定，以后要用git工具将代码提交到github上保存的哦。node.js 因为整个博客框架是基于node.js的，所以必须安装node.js环境，安装过程中一路Next即可。 安装hexo框架&emsp;&emsp;准备工作做好后，我们就可以正式开始博客的搭建。Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。&emsp;&emsp;在桌面鼠标右键，选择Git Bash Here，在弹出的Git命令窗口中输入安装命令，然后回车。 1npm install -g hexo-cli ​&emsp;&emsp;选择一个盘创建一个文件夹，在新建的文件夹内鼠标右键，选择Git Bash Here，输入初始化命令，然后回车，等命令执行完，就会看到生成了一系列的文件。 12hexo initnpm install &emsp;&emsp;接着在该文件夹中继续执行以下命令 12hexo ghexo s &emsp;&emsp;命令执行完后浏览器访问http://localhost:4000 或者 127.0.0.1:4000 ,就会看到hexo的初始界面，是不是有着一丝丝的成就感？但是，这个界面还是在本地，别人并不能看到，想要别人看到，我们就必须将这些文件部署到Github上去。 &emsp;&emsp;前面我们已经在github上创建好了博客仓库，接下来我们编辑博客文件夹下的_config.yml文件，在文件最后找到关键字deploy，对其进行编辑，其中repo后面的值要改成你的仓库地址，注意键值对之间要有空格。 1234deploy: type: git repo: https://github.com/ocean233/ocean233.github.io branch: master &emsp;&emsp;保存修改后，如果前面你的git已经可以推送文件到github上的话，你就可以直接执行以下命令将你的博客部署到GitHub上面。 12hexo ghexo d &emsp;&emsp;但是输入hexo d可能会报ERROR Deployer not fount： git错误，这是因为没有安装hexo-deployer-git这个模块，导致Git不能识别该命令，输入下面指令安装该模块即可。 1npm install hexo-deployer-git --save &emsp;&emsp;安装该模块会有些慢，因为Github毕竟是国外的网站，并不是很稳定，所以大家要耐心等待。安装失败时的话大家多试两遍。等模块安装完再次执行hexo d，这时就会有弹出框，输入自己之前注册的github账号进行登录，然后命令行也会要你输入对应的用户名并弹出输入框让你输入密码，填写完毕敲回车即可正确部署。 &emsp;&emsp;在浏览器输入你的用户名.github.io即可看到你自己搭建的博客了哦，如果上面的步骤都没问题，但是没有看到博客的话，可能是有些延迟，大家等等就好。 基础配置&emsp;&emsp;搭建好的博客还很简单，博客样式说实话也是有点丑的，后面我们可以更换博客的主题，让博客更有特色。现在我们先来修改一下博客的基本配置吧。 &emsp;&emsp;对博客的配置修改主要是对配置文件_config.yml进行修改，我们现在的博客还很简单，所以能做的配置并不多，大家可以参考官网上的一些配置信息https://hexo.io/zh-cn/docs/configuration ，我也会列几个主要配置供大家参考。 12345678# Sitetitle: Ocean&apos;s blogsubtitle: 我的目标是星辰大海description: 大数据技术博客keywords:author: Oceanlanguage: zh-CNtimezone: &emsp;&emsp;这里大家可以修改博客的标题信息等，这是大家对博客进行定制化的第一步。 编写文章&emsp;&emsp;我们搭建博客的主要目的自然是为了向大家分享我们的博客内容，绝对不是为了装B，所以如何写一篇文章才是我们应该关注的重点。 &emsp;&emsp;在你的博客文件夹目录下鼠标右键，点击Git Bash Here，接下来命令敲起来，新建一篇文章。如果没有设置 layout 的话，默认使用_config.yml中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。12$ hexo new [layout] &lt;title&gt;$ hexo new &quot;post title with whitespace&quot; &emsp;&emsp;这时候在/博客目录/source/posts目录下可以看到新建的博客文章，以.md结尾，在这里大家可以使用markdown语法编写自己的博客内容。 &emsp;&emsp;博客内容写好后，回到命令行界面，敲命令将我们的博客内容部署到github上。12hexo ghexo d &emsp;&emsp;如果你想先看看编写的博客文章是怎样的，可以会用hexo s命令，在本地浏览器上先查看，没问题了再部署到github上。到这里，博客的基本操作你就已经熟悉了，可以开始玩转hexo了。","categories":[{"name":"博客","slug":"博客","permalink":"http://yoursite.com/categories/博客/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"博客","slug":"博客","permalink":"http://yoursite.com/tags/博客/"}]}]}